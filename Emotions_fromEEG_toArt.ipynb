{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotions_fromEEG_toArt.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_a7K1sJdokx"
      },
      "source": [
        "# Translating Emotions from EEG to Visual Arts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVAzqXN8dxOI"
      },
      "source": [
        "We assume at this point that the user has already cloned our repo. First of all, enter it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "srczRNOlTee5",
        "outputId": "283a8e81-d17c-4f62-e75f-812f1e02050b"
      },
      "source": [
        "%cd Emotions-fromEEG-toArt/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Emotions-fromEEG-toArt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw6hnovB0SP9"
      },
      "source": [
        "## Install libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFsLzZvq0USx"
      },
      "source": [
        "!pip install torch-scatter \\\n",
        "  torch-sparse \\\n",
        "  torch-cluster \\\n",
        "  torch-spline-conv \\\n",
        "  torch-geometric \\\n",
        "  -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKSqsVFacpLW"
      },
      "source": [
        "!wget https://github.com/ninja-build/ninja/releases/download/v1.8.2/ninja-linux.zip\n",
        "!sudo unzip ninja-linux.zip -d /usr/local/bin/\n",
        "!sudo update-alternatives --install /usr/bin/ninja ninja /usr/local/bin/ninja 1 --force"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek68AcIKH9Z3"
      },
      "source": [
        "## WikiArt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-GiHjuYmnNR"
      },
      "source": [
        "from wikiArt.wikiArt_utils import *"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK0xQdLQlEVT"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB4N5YEgdCk7"
      },
      "source": [
        "!wget http://saifmohammad.com/WebDocs/WikiArt-Emotions.zip\n",
        "!unzip WikiArt-Emotions.zip\n",
        "!cp WikiArt-Emotions/WikiArt-Emotions-Ag4.tsv ./\n",
        "download_wikiArtEmotion(\"wikiArt/dataset\")\n",
        "!rm -r WikiArt-Emotions\n",
        "!rm -r __MACOSX/\n",
        "!rm WikiArt-Emotions-Ag4.tsv\n",
        "!rm WikiArt-Emotions.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QETmCcrK2wK"
      },
      "source": [
        "### Outliers removal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSSqRWbr1fOw"
      },
      "source": [
        "We provide the user with a list of the selected paintings after our pre-processing steps (wikiArt/selection.pkl). In a future distribution, we will provide the code to reproduce such steps and allow users to personalize their version of the wikiArt dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3BgYL__HIPJ"
      },
      "source": [
        "import pickle\n",
        "with open('wikiArt/selection.pkl','rb') as f:\n",
        "  selection=pickle.load(f)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Lk8genHiHV"
      },
      "source": [
        "for image in os.listdir(\"wikiArt/dataset/happiness_optimism\"):\n",
        "  if image not in selection:\n",
        "    !rm \"wikiArt/dataset/happiness_optimism/{image}\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU44pbMERRgG"
      },
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0C-sV43iRPx4",
        "outputId": "db9e1a63-f88f-4789-c82a-1719cec34116"
      },
      "source": [
        "for group in os.listdir(\"wikiArt/dataset\"):\n",
        "  print(\"{}: {}\".format(group,len(os.listdir(os.path.join(\"wikiArt/dataset\",group)))))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sadness_pessimism: 258\n",
            "anger_disgust: 67\n",
            "fear_shame: 214\n",
            "happiness_optimism: 688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5mTYyA3tdp-"
      },
      "source": [
        "data_augmentation(\"wikiArt/dataset\",[\"anger_disgust\",\"fear_shame\",\"sadness_pessimism\"],len(os.listdir(\"wikiArt/dataset/happiness_optimism\")))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IsrbJVDEdJja",
        "outputId": "9661c94b-2c27-489d-f22a-cd1f597291d6"
      },
      "source": [
        "for group in os.listdir(\"wikiArt/dataset\"):\n",
        "  print(\"{}: {}\".format(group,len(os.listdir(os.path.join(\"wikiArt/dataset\",group)))))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sadness_pessimism: 690\n",
            "anger_disgust: 487\n",
            "fear_shame: 690\n",
            "happiness_optimism: 688\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMK8BKwllMXn"
      },
      "source": [
        "### Pre-process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpcXjaGdn9bB"
      },
      "source": [
        "wikiArt_dict=preprocess_wikiart(\"wikiArt/dataset\")\n",
        "np.save(\"wikiArt_dict\",wikiArt_dict)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD_MYpHjli6t"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXuT0PBftpLg"
      },
      "source": [
        "wikiArt_dict=np.load(\"wikiArt_dict.npy\",allow_pickle=True).item()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B1QEDn7trj6"
      },
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True)\n",
        "])\n",
        "\n",
        "BATCH_SIZE=8\n",
        "wikiArt_dataloaders = {\n",
        "    \"anger_disgust\": torch.utils.data.DataLoader(WikiArtDataLoader(wikiArt_dict[\"anger_disgust\"],transform=transform),batch_size=BATCH_SIZE,shuffle=False,num_workers=0,drop_last=True),\n",
        "    \"sadness_pessimism\": torch.utils.data.DataLoader(WikiArtDataLoader(wikiArt_dict[\"sadness_pessimism\"],transform=transform),batch_size=BATCH_SIZE,shuffle=False,num_workers=0,drop_last=True),\n",
        "    \"fear_shame\": torch.utils.data.DataLoader(WikiArtDataLoader(wikiArt_dict[\"fear_shame\"],transform=transform),batch_size=BATCH_SIZE,shuffle=False,num_workers=0,drop_last=True),\n",
        "    \"happiness_optimism\": torch.utils.data.DataLoader(WikiArtDataLoader(wikiArt_dict[\"happiness_optimism\"],transform=transform),batch_size=BATCH_SIZE,shuffle=False,num_workers=0,drop_last=True)\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEmwaQFPSg9w"
      },
      "source": [
        "## SEED-IV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJT6GSbNpSr1"
      },
      "source": [
        "from seed_iv.seedIV_utils import *"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZRLrpR3pd-W"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59SkDF1ShekD"
      },
      "source": [
        "We assume at this point that the user has already got the access to the SEED-IV dataset, and imported a .zip file with the following structure:\n",
        "\n",
        "- **seed-iv.zip**\n",
        " - 1.zip\n",
        " - 2.zip\n",
        " - 3.zip\n",
        " - Channel Order.xlsx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd3nNVqTWKWs",
        "outputId": "dfdfd3fb-b81a-4121-adde-2fecd600ae72"
      },
      "source": [
        "!unzip seed-iv.zip -d seed_iv && rm seed-iv.zip\n",
        "!unzip seed_iv/1.zip -d seed_iv/dataset && rm seed_iv/1.zip\n",
        "!unzip seed_iv/2.zip -d seed_iv/dataset && rm seed_iv/2.zip\n",
        "!unzip seed_iv/3.zip -d seed_iv/dataset && rm seed_iv/3.zip"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  seed-iv.zip\n",
            " extracting: seed_iv/1.zip           \n",
            " extracting: seed_iv/2.zip           \n",
            " extracting: seed_iv/3.zip           \n",
            "  inflating: seed_iv/Channel Order.xlsx  \n",
            "Archive:  seed_iv/1.zip\n",
            "  inflating: seed_iv/dataset/1/1_20160518.mat  \n",
            "  inflating: seed_iv/dataset/1/10_20151014.mat  \n",
            "  inflating: seed_iv/dataset/1/11_20150916.mat  \n",
            "  inflating: seed_iv/dataset/1/12_20150725.mat  \n",
            "  inflating: seed_iv/dataset/1/13_20151115.mat  \n",
            "  inflating: seed_iv/dataset/1/14_20151205.mat  \n",
            "  inflating: seed_iv/dataset/1/15_20150508.mat  \n",
            "  inflating: seed_iv/dataset/1/2_20150915.mat  \n",
            "  inflating: seed_iv/dataset/1/3_20150919.mat  \n",
            "  inflating: seed_iv/dataset/1/4_20151111.mat  \n",
            "  inflating: seed_iv/dataset/1/5_20160406.mat  \n",
            "  inflating: seed_iv/dataset/1/6_20150507.mat  \n",
            "  inflating: seed_iv/dataset/1/7_20150715.mat  \n",
            "  inflating: seed_iv/dataset/1/8_20151103.mat  \n",
            "  inflating: seed_iv/dataset/1/9_20151028.mat  \n",
            "Archive:  seed_iv/2.zip\n",
            "  inflating: seed_iv/dataset/2/1_20161125.mat  \n",
            "  inflating: seed_iv/dataset/2/10_20151021.mat  \n",
            "  inflating: seed_iv/dataset/2/11_20150921.mat  \n",
            "  inflating: seed_iv/dataset/2/12_20150804.mat  \n",
            "  inflating: seed_iv/dataset/2/13_20151125.mat  \n",
            "  inflating: seed_iv/dataset/2/14_20151208.mat  \n",
            "  inflating: seed_iv/dataset/2/15_20150514.mat  \n",
            "  inflating: seed_iv/dataset/2/2_20150920.mat  \n",
            "  inflating: seed_iv/dataset/2/3_20151018.mat  \n",
            "  inflating: seed_iv/dataset/2/4_20151118.mat  \n",
            "  inflating: seed_iv/dataset/2/5_20160413.mat  \n",
            "  inflating: seed_iv/dataset/2/6_20150511.mat  \n",
            "  inflating: seed_iv/dataset/2/7_20150717.mat  \n",
            "  inflating: seed_iv/dataset/2/8_20151110.mat  \n",
            "  inflating: seed_iv/dataset/2/9_20151119.mat  \n",
            "Archive:  seed_iv/3.zip\n",
            "  inflating: seed_iv/dataset/3/1_20161126.mat  \n",
            "  inflating: seed_iv/dataset/3/10_20151023.mat  \n",
            "  inflating: seed_iv/dataset/3/11_20151011.mat  \n",
            "  inflating: seed_iv/dataset/3/12_20150807.mat  \n",
            "  inflating: seed_iv/dataset/3/13_20161130.mat  \n",
            "  inflating: seed_iv/dataset/3/14_20151215.mat  \n",
            "  inflating: seed_iv/dataset/3/15_20150527.mat  \n",
            "  inflating: seed_iv/dataset/3/2_20151012.mat  \n",
            "  inflating: seed_iv/dataset/3/3_20151101.mat  \n",
            "  inflating: seed_iv/dataset/3/4_20151123.mat  \n",
            "  inflating: seed_iv/dataset/3/5_20160420.mat  \n",
            "  inflating: seed_iv/dataset/3/6_20150512.mat  \n",
            "  inflating: seed_iv/dataset/3/7_20150721.mat  \n",
            "  inflating: seed_iv/dataset/3/8_20151117.mat  \n",
            "  inflating: seed_iv/dataset/3/9_20151209.mat  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCMAvvU0pgK0"
      },
      "source": [
        "### Pre-process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqZJgAM7xuft"
      },
      "source": [
        "labels = emotionDL(eps=0.1)\n",
        "eeg_dict=load_data(\"seed_iv/dataset\",labels)\n",
        "np.save(\"eeg_dict\",eeg_dict)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iN-T0LSBdmP",
        "outputId": "df052ac0-ad15-43f9-dc83-7b3f1d562e95"
      },
      "source": [
        "for p in eeg_dict.keys():\n",
        "  print(\"\\nPATIENT {}\".format(p))\n",
        "  print(\"neutral:\\ttrain: {:d}\\tval: {:d}\".format(len(eeg_dict[p][\"neutral\"][\"train\"]),len(eeg_dict[p][\"neutral\"][\"val\"])))\n",
        "  print(\"sadness:\\ttrain: {:d}\\tval: {:d}\".format(len(eeg_dict[p][\"sadness\"][\"train\"]),len(eeg_dict[p][\"sadness\"][\"val\"])))\n",
        "  print(\"fear:\\t\\ttrain: {:d}\\tval: {:d}\".format(len(eeg_dict[p][\"fear\"][\"train\"]),len(eeg_dict[p][\"fear\"][\"val\"])))\n",
        "  print(\"happiness:\\ttrain: {:d}\\tval: {:d}\".format(len(eeg_dict[p][\"happiness\"][\"train\"]),len(eeg_dict[p][\"happiness\"][\"val\"])))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "PATIENT 1\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 6\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 4\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 11\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 5\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 8\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 10\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 7\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 9\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 3\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 2\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 12\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 13\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 14\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 15\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZcPRJkfCJu-"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOgpQ_7ZOWh2"
      },
      "source": [
        "eeg_dict=np.load(\"eeg_dict.npy\",allow_pickle=True).item()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZkzgRmlOWh2"
      },
      "source": [
        "adjacency_matrix=get_adjacency_matrix(\"seed_iv/Channel Order.xlsx\",\"seed_iv/Channel Location.txt\")\n",
        "adjacency_matrix=torch.tensor(adjacency_matrix, dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvxa--JtOWh3"
      },
      "source": [
        "BATCH_SIZE=8\n",
        "eeg_dataloaders = {}\n",
        "for p in eeg_dict.keys():\n",
        "  eeg_dataloaders[p]={\n",
        "    \"neutral\": {\n",
        "      \"train\": torch_geometric.data.DataLoader(eeg_dict[p][\"neutral\"][\"train\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True),\n",
        "      \"val\": torch_geometric.data.DataLoader(eeg_dict[p][\"neutral\"][\"val\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "    },\n",
        "    \"sadness\": {\n",
        "      \"train\": torch_geometric.data.DataLoader(eeg_dict[p][\"sadness\"][\"train\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True),\n",
        "      \"val\": torch_geometric.data.DataLoader(eeg_dict[p][\"sadness\"][\"val\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "    },\n",
        "    \"fear\": {\n",
        "      \"train\": torch_geometric.data.DataLoader(eeg_dict[p][\"fear\"][\"train\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True),\n",
        "      \"val\": torch_geometric.data.DataLoader(eeg_dict[p][\"fear\"][\"val\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "    },\n",
        "    \"happiness\": {\n",
        "      \"train\": torch_geometric.data.DataLoader(eeg_dict[p][\"happiness\"][\"train\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True),\n",
        "      \"val\": torch_geometric.data.DataLoader(eeg_dict[p][\"happiness\"][\"val\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "    }\n",
        "  }"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdWfBdGyaQfA"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIyz1iJzj5W7"
      },
      "source": [
        "PATIENT=15"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH8161TAaUMj"
      },
      "source": [
        "### RGNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhsZLf_Nuwez"
      },
      "source": [
        "from rgnn.RGNN_utils import *"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mmgHr_kClLqo",
        "outputId": "32880a4e-1a6e-469e-80c5-d56afa3af7f6"
      },
      "source": [
        "N_EPOCHS=1000\n",
        "\n",
        "classifier = SymSimGCNNet(62, True,torch.tensor(adjacency_matrix, dtype=torch.float32), 5, (50, 50), 4, 2, dropout=0.7)\n",
        "classifier = classifier.to(device)\n",
        "history, best_model_dict = training_routine(classifier, N_EPOCHS,\n",
        "  EEG_Sampler([\n",
        "    v[\"train\"] for v in eeg_dataloaders[PATIENT].values()\n",
        "  ]),\n",
        "  EEG_Sampler([\n",
        "    v[\"val\"] for v in eeg_dataloaders[PATIENT].values()\n",
        "  ]),\n",
        "  \"./checkpoints\"\n",
        ")\n",
        "plot_history(history)\n",
        "classifier.load_state_dict(best_model_dict);"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/content/Emotions-fromEEG-toArt/rgnn/RGNN_utils.py:167: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = F.log_softmax(x)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2611: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], KL: 21.4349 L1Reg: 0.2018 Total: 21.6367 \n",
            "Epoch [1], KL: 1.9027 L1Reg: 0.2030 Total: 2.1056 \n",
            "Epoch [2], KL: 0.3928 L1Reg: 0.2091 Total: 0.6019 \n",
            "Epoch [3], KL: 0.3368 L1Reg: 0.2109 Total: 0.5477 \n",
            "Epoch [4], KL: 0.3046 L1Reg: 0.2117 Total: 0.5163 \n",
            "Epoch [5], KL: 0.3006 L1Reg: 0.2121 Total: 0.5128 \n",
            "Epoch [6], KL: 0.2887 L1Reg: 0.2124 Total: 0.5011 \n",
            "Epoch [7], KL: 0.2794 L1Reg: 0.2122 Total: 0.4917 \n",
            "Epoch [8], KL: 0.2693 L1Reg: 0.2119 Total: 0.4812 \n",
            "Epoch [9], KL: 0.2656 L1Reg: 0.2115 Total: 0.4771 \n",
            "Epoch [10], KL: 0.2579 L1Reg: 0.2111 Total: 0.4690 \n",
            "Epoch [11], KL: 0.2514 L1Reg: 0.2105 Total: 0.4619 \n",
            "Epoch [12], KL: 0.2728 L1Reg: 0.2102 Total: 0.4830 \n",
            "Epoch [13], KL: 0.2649 L1Reg: 0.2096 Total: 0.4744 \n",
            "Epoch [14], KL: 0.2498 L1Reg: 0.2089 Total: 0.4587 \n",
            "Epoch [15], KL: 0.2474 L1Reg: 0.2082 Total: 0.4555 \n",
            "Epoch [16], KL: 0.2455 L1Reg: 0.2077 Total: 0.4532 \n",
            "Epoch [17], KL: 0.2480 L1Reg: 0.2069 Total: 0.4549 \n",
            "Epoch [18], KL: 0.2513 L1Reg: 0.2062 Total: 0.4575 \n",
            "Epoch [19], KL: 0.2511 L1Reg: 0.2052 Total: 0.4563 \n",
            "Epoch [20], KL: 0.2375 L1Reg: 0.2044 Total: 0.4419 \n",
            "Epoch [21], KL: 0.2376 L1Reg: 0.2034 Total: 0.4410 \n",
            "Epoch [22], KL: 0.2346 L1Reg: 0.2023 Total: 0.4369 \n",
            "Epoch [23], KL: 0.2313 L1Reg: 0.2011 Total: 0.4324 \n",
            "Epoch [24], KL: 0.2360 L1Reg: 0.2002 Total: 0.4362 \n",
            "Epoch [25], KL: 0.2356 L1Reg: 0.1990 Total: 0.4346 \n",
            "Epoch [26], KL: 0.2266 L1Reg: 0.1980 Total: 0.4246 \n",
            "Epoch [27], KL: 0.2273 L1Reg: 0.1969 Total: 0.4242 \n",
            "Epoch [28], KL: 0.2269 L1Reg: 0.1957 Total: 0.4226 \n",
            "Epoch [29], KL: 0.2272 L1Reg: 0.1944 Total: 0.4216 \n",
            "Epoch [30], KL: 0.2266 L1Reg: 0.1932 Total: 0.4198 \n",
            "Epoch [31], KL: 0.2254 L1Reg: 0.1921 Total: 0.4175 \n",
            "Epoch [32], KL: 0.2145 L1Reg: 0.1911 Total: 0.4056 \n",
            "Epoch [33], KL: 0.2146 L1Reg: 0.1900 Total: 0.4046 \n",
            "Epoch [34], KL: 0.2109 L1Reg: 0.1888 Total: 0.3998 \n",
            "Epoch [35], KL: 0.2099 L1Reg: 0.1876 Total: 0.3975 \n",
            "Epoch [36], KL: 0.2203 L1Reg: 0.1865 Total: 0.4068 \n",
            "Epoch [37], KL: 0.2147 L1Reg: 0.1855 Total: 0.4002 \n",
            "Epoch [38], KL: 0.2089 L1Reg: 0.1843 Total: 0.3932 \n",
            "Epoch [39], KL: 0.2055 L1Reg: 0.1834 Total: 0.3889 \n",
            "Epoch [40], KL: 0.2099 L1Reg: 0.1823 Total: 0.3921 \n",
            "Epoch [41], KL: 0.2051 L1Reg: 0.1811 Total: 0.3862 \n",
            "Epoch [42], KL: 0.2169 L1Reg: 0.1801 Total: 0.3970 \n",
            "Epoch [43], KL: 0.1977 L1Reg: 0.1792 Total: 0.3769 \n",
            "Epoch [44], KL: 0.1912 L1Reg: 0.1784 Total: 0.3696 \n",
            "Epoch [45], KL: 0.1869 L1Reg: 0.1773 Total: 0.3642 \n",
            "Epoch [46], KL: 0.1861 L1Reg: 0.1763 Total: 0.3624 \n",
            "Epoch [47], KL: 0.1845 L1Reg: 0.1754 Total: 0.3599 \n",
            "Epoch [48], KL: 0.1943 L1Reg: 0.1746 Total: 0.3688 \n",
            "Epoch [49], KL: 0.1900 L1Reg: 0.1737 Total: 0.3637 \n",
            "Epoch [50], KL: 0.1849 L1Reg: 0.1728 Total: 0.3577 \n",
            "Epoch [51], KL: 0.1786 L1Reg: 0.1720 Total: 0.3506 \n",
            "Epoch [52], KL: 0.1980 L1Reg: 0.1710 Total: 0.3690 \n",
            "Epoch [53], KL: 0.1914 L1Reg: 0.1702 Total: 0.3616 \n",
            "Epoch [54], KL: 0.1946 L1Reg: 0.1694 Total: 0.3640 \n",
            "Epoch [55], KL: 0.1813 L1Reg: 0.1688 Total: 0.3501 \n",
            "Epoch [56], KL: 0.1762 L1Reg: 0.1680 Total: 0.3442 \n",
            "Epoch [57], KL: 0.1822 L1Reg: 0.1673 Total: 0.3495 \n",
            "Epoch [58], KL: 0.1654 L1Reg: 0.1665 Total: 0.3319 \n",
            "Epoch [59], KL: 0.1653 L1Reg: 0.1659 Total: 0.3312 \n",
            "Epoch [60], KL: 0.1691 L1Reg: 0.1654 Total: 0.3345 \n",
            "Epoch [61], KL: 0.1782 L1Reg: 0.1651 Total: 0.3433 \n",
            "Epoch [62], KL: 0.1755 L1Reg: 0.1644 Total: 0.3399 \n",
            "Epoch [63], KL: 0.1934 L1Reg: 0.1638 Total: 0.3572 \n",
            "Epoch [64], KL: 0.1661 L1Reg: 0.1629 Total: 0.3290 \n",
            "Epoch [65], KL: 0.1836 L1Reg: 0.1624 Total: 0.3461 \n",
            "Epoch [66], KL: 0.2138 L1Reg: 0.1619 Total: 0.3757 \n",
            "Epoch [67], KL: 0.1646 L1Reg: 0.1614 Total: 0.3260 \n",
            "Epoch [68], KL: 0.1613 L1Reg: 0.1608 Total: 0.3220 \n",
            "Epoch [69], KL: 0.1618 L1Reg: 0.1601 Total: 0.3219 \n",
            "Epoch [70], KL: 0.1529 L1Reg: 0.1595 Total: 0.3124 \n",
            "Epoch [71], KL: 0.1628 L1Reg: 0.1590 Total: 0.3218 \n",
            "Epoch [72], KL: 0.1829 L1Reg: 0.1586 Total: 0.3415 \n",
            "Epoch [73], KL: 0.1570 L1Reg: 0.1581 Total: 0.3152 \n",
            "Epoch [74], KL: 0.1518 L1Reg: 0.1576 Total: 0.3094 \n",
            "Epoch [75], KL: 0.1511 L1Reg: 0.1569 Total: 0.3081 \n",
            "Epoch [76], KL: 0.1520 L1Reg: 0.1562 Total: 0.3082 \n",
            "Epoch [77], KL: 0.1391 L1Reg: 0.1557 Total: 0.2947 \n",
            "Epoch [78], KL: 0.1748 L1Reg: 0.1553 Total: 0.3301 \n",
            "Epoch [79], KL: 0.1849 L1Reg: 0.1547 Total: 0.3396 \n",
            "Epoch [80], KL: 0.1396 L1Reg: 0.1541 Total: 0.2937 \n",
            "Epoch [81], KL: 0.1369 L1Reg: 0.1535 Total: 0.2903 \n",
            "Epoch [82], KL: 0.1389 L1Reg: 0.1529 Total: 0.2919 \n",
            "Epoch [83], KL: 0.1316 L1Reg: 0.1524 Total: 0.2839 \n",
            "Epoch [84], KL: 0.1556 L1Reg: 0.1522 Total: 0.3078 \n",
            "Epoch [85], KL: 0.1337 L1Reg: 0.1516 Total: 0.2853 \n",
            "Epoch [86], KL: 0.1321 L1Reg: 0.1510 Total: 0.2831 \n",
            "Epoch [87], KL: 0.1262 L1Reg: 0.1504 Total: 0.2767 \n",
            "Epoch [88], KL: 0.1210 L1Reg: 0.1499 Total: 0.2709 \n",
            "Epoch [89], KL: 0.1522 L1Reg: 0.1493 Total: 0.3015 \n",
            "Epoch [90], KL: 0.1478 L1Reg: 0.1489 Total: 0.2967 \n",
            "Epoch [91], KL: 0.1375 L1Reg: 0.1486 Total: 0.2861 \n",
            "Epoch [92], KL: 0.1359 L1Reg: 0.1480 Total: 0.2839 \n",
            "Epoch [93], KL: 0.1238 L1Reg: 0.1476 Total: 0.2714 \n",
            "Epoch [94], KL: 0.1303 L1Reg: 0.1471 Total: 0.2774 \n",
            "Epoch [95], KL: 0.1230 L1Reg: 0.1466 Total: 0.2696 \n",
            "Epoch [96], KL: 0.1718 L1Reg: 0.1462 Total: 0.3180 \n",
            "Epoch [97], KL: 0.1439 L1Reg: 0.1456 Total: 0.2895 \n",
            "Epoch [98], KL: 0.1422 L1Reg: 0.1450 Total: 0.2872 \n",
            "Epoch [99], KL: 0.1405 L1Reg: 0.1446 Total: 0.2851 \n",
            "Epoch [100], KL: 0.1134 L1Reg: 0.1440 Total: 0.2574 \n",
            "Epoch [101], KL: 0.1229 L1Reg: 0.1435 Total: 0.2664 \n",
            "Epoch [102], KL: 0.1532 L1Reg: 0.1431 Total: 0.2963 \n",
            "Epoch [103], KL: 0.1190 L1Reg: 0.1427 Total: 0.2617 \n",
            "Epoch [104], KL: 0.1244 L1Reg: 0.1421 Total: 0.2665 \n",
            "Epoch [105], KL: 0.1424 L1Reg: 0.1417 Total: 0.2841 \n",
            "Epoch [106], KL: 0.1118 L1Reg: 0.1412 Total: 0.2530 \n",
            "Epoch [107], KL: 0.1176 L1Reg: 0.1406 Total: 0.2581 \n",
            "Epoch [108], KL: 0.1417 L1Reg: 0.1402 Total: 0.2819 \n",
            "Epoch [109], KL: 0.1122 L1Reg: 0.1397 Total: 0.2519 \n",
            "Epoch [110], KL: 0.1212 L1Reg: 0.1391 Total: 0.2603 \n",
            "Epoch [111], KL: 0.1097 L1Reg: 0.1387 Total: 0.2484 \n",
            "Epoch [112], KL: 0.1007 L1Reg: 0.1381 Total: 0.2389 \n",
            "Epoch [113], KL: 0.1079 L1Reg: 0.1376 Total: 0.2456 \n",
            "Epoch [114], KL: 0.1285 L1Reg: 0.1372 Total: 0.2657 \n",
            "Epoch [115], KL: 0.1063 L1Reg: 0.1368 Total: 0.2431 \n",
            "Epoch [116], KL: 0.1125 L1Reg: 0.1364 Total: 0.2489 \n",
            "Epoch [117], KL: 0.1435 L1Reg: 0.1360 Total: 0.2795 \n",
            "Epoch [118], KL: 0.1297 L1Reg: 0.1356 Total: 0.2654 \n",
            "Epoch [119], KL: 0.1075 L1Reg: 0.1349 Total: 0.2425 \n",
            "Epoch [120], KL: 0.1454 L1Reg: 0.1344 Total: 0.2798 \n",
            "Epoch [121], KL: 0.1166 L1Reg: 0.1341 Total: 0.2507 \n",
            "Epoch [122], KL: 0.1140 L1Reg: 0.1336 Total: 0.2476 \n",
            "Epoch [123], KL: 0.1181 L1Reg: 0.1331 Total: 0.2512 \n",
            "Epoch [124], KL: 0.1164 L1Reg: 0.1326 Total: 0.2490 \n",
            "Epoch [125], KL: 0.1049 L1Reg: 0.1320 Total: 0.2369 \n",
            "Epoch [126], KL: 0.1413 L1Reg: 0.1318 Total: 0.2731 \n",
            "Epoch [127], KL: 0.1079 L1Reg: 0.1313 Total: 0.2392 \n",
            "Epoch [128], KL: 0.1223 L1Reg: 0.1311 Total: 0.2534 \n",
            "Epoch [129], KL: 0.1016 L1Reg: 0.1305 Total: 0.2321 \n",
            "Epoch [130], KL: 0.1215 L1Reg: 0.1301 Total: 0.2516 \n",
            "Epoch [131], KL: 0.1484 L1Reg: 0.1296 Total: 0.2780 \n",
            "Epoch [132], KL: 0.1328 L1Reg: 0.1292 Total: 0.2620 \n",
            "Epoch [133], KL: 0.1106 L1Reg: 0.1286 Total: 0.2392 \n",
            "Epoch [134], KL: 0.1303 L1Reg: 0.1281 Total: 0.2584 \n",
            "Epoch [135], KL: 0.1379 L1Reg: 0.1277 Total: 0.2656 \n",
            "Epoch [136], KL: 0.1053 L1Reg: 0.1272 Total: 0.2325 \n",
            "Epoch [137], KL: 0.0986 L1Reg: 0.1270 Total: 0.2256 \n",
            "Epoch [138], KL: 0.1193 L1Reg: 0.1267 Total: 0.2459 \n",
            "Epoch [139], KL: 0.0974 L1Reg: 0.1262 Total: 0.2236 \n",
            "Epoch [140], KL: 0.1015 L1Reg: 0.1257 Total: 0.2272 \n",
            "Epoch [141], KL: 0.1067 L1Reg: 0.1252 Total: 0.2319 \n",
            "Epoch [142], KL: 0.0925 L1Reg: 0.1250 Total: 0.2175 \n",
            "Epoch [143], KL: 0.1040 L1Reg: 0.1246 Total: 0.2286 \n",
            "Epoch [144], KL: 0.1222 L1Reg: 0.1241 Total: 0.2463 \n",
            "Epoch [145], KL: 0.1063 L1Reg: 0.1236 Total: 0.2298 \n",
            "Epoch [146], KL: 0.1022 L1Reg: 0.1234 Total: 0.2256 \n",
            "Epoch [147], KL: 0.1105 L1Reg: 0.1229 Total: 0.2334 \n",
            "Epoch [148], KL: 0.1068 L1Reg: 0.1225 Total: 0.2292 \n",
            "Epoch [149], KL: 0.1034 L1Reg: 0.1219 Total: 0.2253 \n",
            "Epoch [150], KL: 0.1250 L1Reg: 0.1215 Total: 0.2465 \n",
            "Epoch [151], KL: 0.1038 L1Reg: 0.1211 Total: 0.2249 \n",
            "Epoch [152], KL: 0.1270 L1Reg: 0.1205 Total: 0.2475 \n",
            "Epoch [153], KL: 0.1266 L1Reg: 0.1202 Total: 0.2468 \n",
            "Epoch [154], KL: 0.1262 L1Reg: 0.1199 Total: 0.2461 \n",
            "Epoch [155], KL: 0.1086 L1Reg: 0.1194 Total: 0.2280 \n",
            "Epoch [156], KL: 0.1226 L1Reg: 0.1190 Total: 0.2416 \n",
            "Epoch [157], KL: 0.1195 L1Reg: 0.1186 Total: 0.2381 \n",
            "Epoch [158], KL: 0.0995 L1Reg: 0.1182 Total: 0.2177 \n",
            "Epoch [159], KL: 0.1203 L1Reg: 0.1179 Total: 0.2382 \n",
            "Epoch [160], KL: 0.1181 L1Reg: 0.1174 Total: 0.2355 \n",
            "Epoch [161], KL: 0.1097 L1Reg: 0.1170 Total: 0.2267 \n",
            "Epoch [162], KL: 0.1269 L1Reg: 0.1165 Total: 0.2434 \n",
            "Epoch [163], KL: 0.1085 L1Reg: 0.1163 Total: 0.2248 \n",
            "Epoch [164], KL: 0.1074 L1Reg: 0.1159 Total: 0.2233 \n",
            "Epoch [165], KL: 0.0943 L1Reg: 0.1155 Total: 0.2098 \n",
            "Epoch [166], KL: 0.0941 L1Reg: 0.1150 Total: 0.2090 \n",
            "Epoch [167], KL: 0.1121 L1Reg: 0.1148 Total: 0.2269 \n",
            "Epoch [168], KL: 0.1116 L1Reg: 0.1143 Total: 0.2259 \n",
            "Epoch [169], KL: 0.1088 L1Reg: 0.1141 Total: 0.2229 \n",
            "Epoch [170], KL: 0.1117 L1Reg: 0.1134 Total: 0.2251 \n",
            "Epoch [171], KL: 0.1078 L1Reg: 0.1131 Total: 0.2209 \n",
            "Epoch [172], KL: 0.0978 L1Reg: 0.1128 Total: 0.2106 \n",
            "Epoch [173], KL: 0.1008 L1Reg: 0.1123 Total: 0.2131 \n",
            "Epoch [174], KL: 0.1154 L1Reg: 0.1119 Total: 0.2273 \n",
            "Epoch [175], KL: 0.1116 L1Reg: 0.1116 Total: 0.2232 \n",
            "Epoch [176], KL: 0.1207 L1Reg: 0.1112 Total: 0.2319 \n",
            "Epoch [177], KL: 0.1180 L1Reg: 0.1108 Total: 0.2288 \n",
            "Epoch [178], KL: 0.1145 L1Reg: 0.1104 Total: 0.2249 \n",
            "Epoch [179], KL: 0.0993 L1Reg: 0.1098 Total: 0.2091 \n",
            "Epoch [180], KL: 0.1227 L1Reg: 0.1097 Total: 0.2324 \n",
            "Epoch [181], KL: 0.0971 L1Reg: 0.1094 Total: 0.2065 \n",
            "Epoch [182], KL: 0.1156 L1Reg: 0.1089 Total: 0.2245 \n",
            "Epoch [183], KL: 0.1220 L1Reg: 0.1086 Total: 0.2306 \n",
            "Epoch [184], KL: 0.0942 L1Reg: 0.1083 Total: 0.2025 \n",
            "Epoch [185], KL: 0.1043 L1Reg: 0.1077 Total: 0.2121 \n",
            "Epoch [186], KL: 0.1236 L1Reg: 0.1074 Total: 0.2309 \n",
            "Epoch [187], KL: 0.1170 L1Reg: 0.1071 Total: 0.2241 \n",
            "Epoch [188], KL: 0.1150 L1Reg: 0.1067 Total: 0.2217 \n",
            "Epoch [189], KL: 0.1212 L1Reg: 0.1064 Total: 0.2276 \n",
            "Epoch [190], KL: 0.1230 L1Reg: 0.1058 Total: 0.2289 \n",
            "Epoch [191], KL: 0.0946 L1Reg: 0.1056 Total: 0.2002 \n",
            "Epoch [192], KL: 0.1091 L1Reg: 0.1050 Total: 0.2141 \n",
            "Epoch [193], KL: 0.1217 L1Reg: 0.1052 Total: 0.2269 \n",
            "Epoch [194], KL: 0.0940 L1Reg: 0.1047 Total: 0.1987 \n",
            "Epoch [195], KL: 0.1028 L1Reg: 0.1044 Total: 0.2072 \n",
            "Epoch [196], KL: 0.1248 L1Reg: 0.1042 Total: 0.2291 \n",
            "Epoch [197], KL: 0.0961 L1Reg: 0.1035 Total: 0.1997 \n",
            "Epoch [198], KL: 0.1268 L1Reg: 0.1032 Total: 0.2300 \n",
            "Epoch [199], KL: 0.0962 L1Reg: 0.1028 Total: 0.1990 \n",
            "Epoch [200], KL: 0.1047 L1Reg: 0.1025 Total: 0.2072 \n",
            "Epoch [201], KL: 0.1124 L1Reg: 0.1023 Total: 0.2147 \n",
            "Epoch [202], KL: 0.0837 L1Reg: 0.1017 Total: 0.1854 \n",
            "Epoch [203], KL: 0.1037 L1Reg: 0.1016 Total: 0.2053 \n",
            "Epoch [204], KL: 0.1230 L1Reg: 0.1013 Total: 0.2243 \n",
            "Epoch [205], KL: 0.1052 L1Reg: 0.1014 Total: 0.2066 \n",
            "Epoch [206], KL: 0.1160 L1Reg: 0.1010 Total: 0.2170 \n",
            "Epoch [207], KL: 0.1030 L1Reg: 0.1006 Total: 0.2036 \n",
            "Epoch [208], KL: 0.1115 L1Reg: 0.1003 Total: 0.2117 \n",
            "Epoch [209], KL: 0.1206 L1Reg: 0.0998 Total: 0.2204 \n",
            "Epoch [210], KL: 0.1139 L1Reg: 0.0994 Total: 0.2133 \n",
            "Epoch [211], KL: 0.1060 L1Reg: 0.0991 Total: 0.2051 \n",
            "Epoch [212], KL: 0.1041 L1Reg: 0.0986 Total: 0.2027 \n",
            "Epoch [213], KL: 0.1237 L1Reg: 0.0985 Total: 0.2222 \n",
            "Epoch [214], KL: 0.1065 L1Reg: 0.0979 Total: 0.2044 \n",
            "Epoch [215], KL: 0.1252 L1Reg: 0.0976 Total: 0.2228 \n",
            "Epoch [216], KL: 0.1189 L1Reg: 0.0972 Total: 0.2161 \n",
            "Epoch [217], KL: 0.1029 L1Reg: 0.0969 Total: 0.1998 \n",
            "Epoch [218], KL: 0.1048 L1Reg: 0.0966 Total: 0.2014 \n",
            "Epoch [219], KL: 0.0907 L1Reg: 0.0964 Total: 0.1871 \n",
            "Epoch [220], KL: 0.0862 L1Reg: 0.0961 Total: 0.1823 \n",
            "Epoch [221], KL: 0.1051 L1Reg: 0.0959 Total: 0.2010 \n",
            "Epoch [222], KL: 0.1168 L1Reg: 0.0955 Total: 0.2123 \n",
            "Epoch [223], KL: 0.0899 L1Reg: 0.0954 Total: 0.1853 \n",
            "Epoch [224], KL: 0.1077 L1Reg: 0.0949 Total: 0.2026 \n",
            "Epoch [225], KL: 0.1116 L1Reg: 0.0949 Total: 0.2065 \n",
            "Epoch [226], KL: 0.1049 L1Reg: 0.0944 Total: 0.1993 \n",
            "Epoch [227], KL: 0.1053 L1Reg: 0.0939 Total: 0.1993 \n",
            "Epoch [228], KL: 0.1185 L1Reg: 0.0938 Total: 0.2123 \n",
            "Epoch [229], KL: 0.1144 L1Reg: 0.0935 Total: 0.2078 \n",
            "Epoch [230], KL: 0.1069 L1Reg: 0.0930 Total: 0.1999 \n",
            "Epoch [231], KL: 0.1334 L1Reg: 0.0926 Total: 0.2260 \n",
            "Epoch [232], KL: 0.1260 L1Reg: 0.0923 Total: 0.2183 \n",
            "Epoch [233], KL: 0.1080 L1Reg: 0.0920 Total: 0.2000 \n",
            "Epoch [234], KL: 0.1237 L1Reg: 0.0916 Total: 0.2153 \n",
            "Epoch [235], KL: 0.0978 L1Reg: 0.0913 Total: 0.1891 \n",
            "Epoch [236], KL: 0.1088 L1Reg: 0.0909 Total: 0.1997 \n",
            "Epoch [237], KL: 0.1141 L1Reg: 0.0905 Total: 0.2046 \n",
            "Epoch [238], KL: 0.1165 L1Reg: 0.0904 Total: 0.2069 \n",
            "Epoch [239], KL: 0.1155 L1Reg: 0.0900 Total: 0.2055 \n",
            "Epoch [240], KL: 0.1193 L1Reg: 0.0894 Total: 0.2087 \n",
            "Epoch [241], KL: 0.1131 L1Reg: 0.0891 Total: 0.2022 \n",
            "Epoch [242], KL: 0.1084 L1Reg: 0.0886 Total: 0.1970 \n",
            "Epoch [243], KL: 0.1401 L1Reg: 0.0883 Total: 0.2284 \n",
            "Epoch [244], KL: 0.1032 L1Reg: 0.0878 Total: 0.1910 \n",
            "Epoch [245], KL: 0.1241 L1Reg: 0.0878 Total: 0.2119 \n",
            "Epoch [246], KL: 0.0998 L1Reg: 0.0874 Total: 0.1872 \n",
            "Epoch [247], KL: 0.0951 L1Reg: 0.0872 Total: 0.1823 \n",
            "Epoch [248], KL: 0.1144 L1Reg: 0.0865 Total: 0.2008 \n",
            "Epoch [249], KL: 0.0934 L1Reg: 0.0860 Total: 0.1794 \n",
            "Epoch [250], KL: 0.0988 L1Reg: 0.0858 Total: 0.1847 \n",
            "Epoch [251], KL: 0.1041 L1Reg: 0.0854 Total: 0.1895 \n",
            "Epoch [252], KL: 0.1109 L1Reg: 0.0854 Total: 0.1963 \n",
            "Epoch [253], KL: 0.1051 L1Reg: 0.0853 Total: 0.1905 \n",
            "Epoch [254], KL: 0.1168 L1Reg: 0.0848 Total: 0.2016 \n",
            "Epoch [255], KL: 0.1124 L1Reg: 0.0842 Total: 0.1966 \n",
            "Epoch [256], KL: 0.0906 L1Reg: 0.0839 Total: 0.1745 \n",
            "Epoch [257], KL: 0.0921 L1Reg: 0.0834 Total: 0.1755 \n",
            "Epoch [258], KL: 0.1241 L1Reg: 0.0833 Total: 0.2074 \n",
            "Epoch [259], KL: 0.1148 L1Reg: 0.0831 Total: 0.1979 \n",
            "Epoch [260], KL: 0.1198 L1Reg: 0.0825 Total: 0.2023 \n",
            "Epoch [261], KL: 0.1208 L1Reg: 0.0820 Total: 0.2029 \n",
            "Epoch [262], KL: 0.0990 L1Reg: 0.0816 Total: 0.1806 \n",
            "Epoch [263], KL: 0.1069 L1Reg: 0.0813 Total: 0.1882 \n",
            "Epoch [264], KL: 0.1251 L1Reg: 0.0807 Total: 0.2059 \n",
            "Epoch [265], KL: 0.0983 L1Reg: 0.0804 Total: 0.1787 \n",
            "Epoch [266], KL: 0.1157 L1Reg: 0.0802 Total: 0.1959 \n",
            "Epoch [267], KL: 0.1351 L1Reg: 0.0799 Total: 0.2150 \n",
            "Epoch [268], KL: 0.1154 L1Reg: 0.0795 Total: 0.1948 \n",
            "Epoch [269], KL: 0.1088 L1Reg: 0.0790 Total: 0.1878 \n",
            "Epoch [270], KL: 0.1116 L1Reg: 0.0784 Total: 0.1900 \n",
            "Epoch [271], KL: 0.1124 L1Reg: 0.0786 Total: 0.1910 \n",
            "Epoch [272], KL: 0.1098 L1Reg: 0.0780 Total: 0.1878 \n",
            "Epoch [273], KL: 0.1081 L1Reg: 0.0774 Total: 0.1855 \n",
            "Epoch [274], KL: 0.1095 L1Reg: 0.0771 Total: 0.1866 \n",
            "Epoch [275], KL: 0.0977 L1Reg: 0.0766 Total: 0.1743 \n",
            "Epoch [276], KL: 0.0917 L1Reg: 0.0762 Total: 0.1679 \n",
            "Epoch [277], KL: 0.0868 L1Reg: 0.0761 Total: 0.1629 \n",
            "Epoch [278], KL: 0.0940 L1Reg: 0.0756 Total: 0.1695 \n",
            "Epoch [279], KL: 0.1100 L1Reg: 0.0751 Total: 0.1851 \n",
            "Epoch [280], KL: 0.1094 L1Reg: 0.0749 Total: 0.1843 \n",
            "Epoch [281], KL: 0.0999 L1Reg: 0.0746 Total: 0.1745 \n",
            "Epoch [282], KL: 0.1145 L1Reg: 0.0741 Total: 0.1886 \n",
            "Epoch [283], KL: 0.0996 L1Reg: 0.0737 Total: 0.1733 \n",
            "Epoch [284], KL: 0.1125 L1Reg: 0.0733 Total: 0.1858 \n",
            "Epoch [285], KL: 0.1246 L1Reg: 0.0729 Total: 0.1975 \n",
            "Epoch [286], KL: 0.1219 L1Reg: 0.0720 Total: 0.1940 \n",
            "Epoch [287], KL: 0.1148 L1Reg: 0.0720 Total: 0.1868 \n",
            "Epoch [288], KL: 0.1181 L1Reg: 0.0712 Total: 0.1893 \n",
            "Epoch [289], KL: 0.1052 L1Reg: 0.0713 Total: 0.1765 \n",
            "Epoch [290], KL: 0.0965 L1Reg: 0.0706 Total: 0.1671 \n",
            "Epoch [291], KL: 0.0953 L1Reg: 0.0705 Total: 0.1658 \n",
            "Epoch [292], KL: 0.1055 L1Reg: 0.0699 Total: 0.1754 \n",
            "Epoch [293], KL: 0.0994 L1Reg: 0.0696 Total: 0.1690 \n",
            "Epoch [294], KL: 0.1174 L1Reg: 0.0690 Total: 0.1864 \n",
            "Epoch [295], KL: 0.1051 L1Reg: 0.0688 Total: 0.1740 \n",
            "Epoch [296], KL: 0.1110 L1Reg: 0.0681 Total: 0.1791 \n",
            "Epoch [297], KL: 0.1116 L1Reg: 0.0679 Total: 0.1795 \n",
            "Epoch [298], KL: 0.1106 L1Reg: 0.0677 Total: 0.1784 \n",
            "Epoch [299], KL: 0.1080 L1Reg: 0.0672 Total: 0.1752 \n",
            "Epoch [300], KL: 0.0895 L1Reg: 0.0665 Total: 0.1560 \n",
            "Epoch [301], KL: 0.0945 L1Reg: 0.0664 Total: 0.1609 \n",
            "Epoch [302], KL: 0.0948 L1Reg: 0.0659 Total: 0.1607 \n",
            "Epoch [303], KL: 0.0922 L1Reg: 0.0654 Total: 0.1575 \n",
            "Epoch [304], KL: 0.0870 L1Reg: 0.0647 Total: 0.1517 \n",
            "Epoch [305], KL: 0.0882 L1Reg: 0.0643 Total: 0.1525 \n",
            "Epoch [306], KL: 0.1230 L1Reg: 0.0638 Total: 0.1868 \n",
            "Epoch [307], KL: 0.0865 L1Reg: 0.0635 Total: 0.1500 \n",
            "Epoch [308], KL: 0.0986 L1Reg: 0.0631 Total: 0.1617 \n",
            "Epoch [309], KL: 0.1024 L1Reg: 0.0625 Total: 0.1650 \n",
            "Epoch [310], KL: 0.1045 L1Reg: 0.0619 Total: 0.1664 \n",
            "Epoch [311], KL: 0.0977 L1Reg: 0.0615 Total: 0.1592 \n",
            "Epoch [312], KL: 0.1154 L1Reg: 0.0607 Total: 0.1761 \n",
            "Epoch [313], KL: 0.1337 L1Reg: 0.0607 Total: 0.1944 \n",
            "Epoch [314], KL: 0.1107 L1Reg: 0.0605 Total: 0.1711 \n",
            "Epoch [315], KL: 0.1169 L1Reg: 0.0598 Total: 0.1767 \n",
            "Epoch [316], KL: 0.1014 L1Reg: 0.0595 Total: 0.1610 \n",
            "Epoch [317], KL: 0.0887 L1Reg: 0.0591 Total: 0.1477 \n",
            "Epoch [318], KL: 0.1013 L1Reg: 0.0586 Total: 0.1599 \n",
            "Epoch [319], KL: 0.0994 L1Reg: 0.0585 Total: 0.1579 \n",
            "Epoch [320], KL: 0.1066 L1Reg: 0.0579 Total: 0.1644 \n",
            "Epoch [321], KL: 0.0955 L1Reg: 0.0574 Total: 0.1529 \n",
            "Epoch [322], KL: 0.1080 L1Reg: 0.0571 Total: 0.1651 \n",
            "Epoch [323], KL: 0.1084 L1Reg: 0.0568 Total: 0.1653 \n",
            "Epoch [324], KL: 0.1088 L1Reg: 0.0561 Total: 0.1649 \n",
            "Epoch [325], KL: 0.1023 L1Reg: 0.0556 Total: 0.1579 \n",
            "Epoch [326], KL: 0.1085 L1Reg: 0.0549 Total: 0.1634 \n",
            "Epoch [327], KL: 0.0923 L1Reg: 0.0549 Total: 0.1472 \n",
            "Epoch [328], KL: 0.0865 L1Reg: 0.0543 Total: 0.1408 \n",
            "Epoch [329], KL: 0.0931 L1Reg: 0.0539 Total: 0.1470 \n",
            "Epoch [330], KL: 0.1040 L1Reg: 0.0534 Total: 0.1573 \n",
            "Epoch [331], KL: 0.0853 L1Reg: 0.0532 Total: 0.1385 \n",
            "Epoch [332], KL: 0.0875 L1Reg: 0.0529 Total: 0.1403 \n",
            "Epoch [333], KL: 0.1018 L1Reg: 0.0522 Total: 0.1540 \n",
            "Epoch [334], KL: 0.0934 L1Reg: 0.0518 Total: 0.1452 \n",
            "Epoch [335], KL: 0.0844 L1Reg: 0.0511 Total: 0.1355 \n",
            "Epoch [336], KL: 0.1037 L1Reg: 0.0509 Total: 0.1545 \n",
            "Epoch [337], KL: 0.1042 L1Reg: 0.0504 Total: 0.1547 \n",
            "Epoch [338], KL: 0.1084 L1Reg: 0.0500 Total: 0.1584 \n",
            "Epoch [339], KL: 0.1135 L1Reg: 0.0493 Total: 0.1629 \n",
            "Epoch [340], KL: 0.1096 L1Reg: 0.0491 Total: 0.1587 \n",
            "Epoch [341], KL: 0.1065 L1Reg: 0.0490 Total: 0.1555 \n",
            "Epoch [342], KL: 0.1036 L1Reg: 0.0486 Total: 0.1522 \n",
            "Epoch [343], KL: 0.0941 L1Reg: 0.0483 Total: 0.1423 \n",
            "Epoch [344], KL: 0.1023 L1Reg: 0.0478 Total: 0.1501 \n",
            "Epoch [345], KL: 0.0946 L1Reg: 0.0473 Total: 0.1419 \n",
            "Epoch [346], KL: 0.0930 L1Reg: 0.0469 Total: 0.1399 \n",
            "Epoch [347], KL: 0.0859 L1Reg: 0.0465 Total: 0.1324 \n",
            "Epoch [348], KL: 0.1104 L1Reg: 0.0460 Total: 0.1564 \n",
            "Epoch [349], KL: 0.1093 L1Reg: 0.0460 Total: 0.1553 \n",
            "Epoch [350], KL: 0.1203 L1Reg: 0.0454 Total: 0.1658 \n",
            "Epoch [351], KL: 0.1032 L1Reg: 0.0451 Total: 0.1484 \n",
            "Epoch [352], KL: 0.1013 L1Reg: 0.0448 Total: 0.1461 \n",
            "Epoch [353], KL: 0.0861 L1Reg: 0.0445 Total: 0.1306 \n",
            "Epoch [354], KL: 0.0956 L1Reg: 0.0439 Total: 0.1395 \n",
            "Epoch [355], KL: 0.0970 L1Reg: 0.0442 Total: 0.1412 \n",
            "Epoch [356], KL: 0.0884 L1Reg: 0.0436 Total: 0.1320 \n",
            "Epoch [357], KL: 0.0944 L1Reg: 0.0431 Total: 0.1375 \n",
            "Epoch [358], KL: 0.0958 L1Reg: 0.0427 Total: 0.1385 \n",
            "Epoch [359], KL: 0.0979 L1Reg: 0.0422 Total: 0.1401 \n",
            "Epoch [360], KL: 0.1042 L1Reg: 0.0420 Total: 0.1462 \n",
            "Epoch [361], KL: 0.0853 L1Reg: 0.0417 Total: 0.1270 \n",
            "Epoch [362], KL: 0.1005 L1Reg: 0.0411 Total: 0.1416 \n",
            "Epoch [363], KL: 0.1055 L1Reg: 0.0408 Total: 0.1463 \n",
            "Epoch [364], KL: 0.1075 L1Reg: 0.0407 Total: 0.1482 \n",
            "Epoch [365], KL: 0.1102 L1Reg: 0.0402 Total: 0.1504 \n",
            "Epoch [366], KL: 0.1126 L1Reg: 0.0398 Total: 0.1525 \n",
            "Epoch [367], KL: 0.1011 L1Reg: 0.0400 Total: 0.1411 \n",
            "Epoch [368], KL: 0.1112 L1Reg: 0.0395 Total: 0.1507 \n",
            "Epoch [369], KL: 0.1052 L1Reg: 0.0391 Total: 0.1443 \n",
            "Epoch [370], KL: 0.0845 L1Reg: 0.0385 Total: 0.1230 \n",
            "Epoch [371], KL: 0.0925 L1Reg: 0.0384 Total: 0.1308 \n",
            "Epoch [372], KL: 0.1016 L1Reg: 0.0378 Total: 0.1394 \n",
            "Epoch [373], KL: 0.0890 L1Reg: 0.0376 Total: 0.1266 \n",
            "Epoch [374], KL: 0.0886 L1Reg: 0.0371 Total: 0.1257 \n",
            "Epoch [375], KL: 0.1020 L1Reg: 0.0370 Total: 0.1390 \n",
            "Epoch [376], KL: 0.1017 L1Reg: 0.0367 Total: 0.1385 \n",
            "Epoch [377], KL: 0.1062 L1Reg: 0.0364 Total: 0.1426 \n",
            "Epoch [378], KL: 0.1125 L1Reg: 0.0364 Total: 0.1489 \n",
            "Epoch [379], KL: 0.0962 L1Reg: 0.0360 Total: 0.1322 \n",
            "Epoch [380], KL: 0.0922 L1Reg: 0.0352 Total: 0.1274 \n",
            "Epoch [381], KL: 0.0831 L1Reg: 0.0356 Total: 0.1187 \n",
            "Epoch [382], KL: 0.0981 L1Reg: 0.0351 Total: 0.1331 \n",
            "Epoch [383], KL: 0.0864 L1Reg: 0.0347 Total: 0.1211 \n",
            "Epoch [384], KL: 0.0796 L1Reg: 0.0343 Total: 0.1139 \n",
            "Epoch [385], KL: 0.0923 L1Reg: 0.0346 Total: 0.1269 \n",
            "Epoch [386], KL: 0.0843 L1Reg: 0.0340 Total: 0.1183 \n",
            "Epoch [387], KL: 0.0905 L1Reg: 0.0336 Total: 0.1241 \n",
            "Epoch [388], KL: 0.0981 L1Reg: 0.0334 Total: 0.1315 \n",
            "Epoch [389], KL: 0.0945 L1Reg: 0.0327 Total: 0.1272 \n",
            "Epoch [390], KL: 0.1187 L1Reg: 0.0329 Total: 0.1516 \n",
            "Epoch [391], KL: 0.1037 L1Reg: 0.0328 Total: 0.1365 \n",
            "Epoch [392], KL: 0.1072 L1Reg: 0.0325 Total: 0.1396 \n",
            "Epoch [393], KL: 0.1157 L1Reg: 0.0324 Total: 0.1481 \n",
            "Epoch [394], KL: 0.0990 L1Reg: 0.0322 Total: 0.1311 \n",
            "Epoch [395], KL: 0.0979 L1Reg: 0.0321 Total: 0.1300 \n",
            "Epoch [396], KL: 0.0984 L1Reg: 0.0318 Total: 0.1302 \n",
            "Epoch [397], KL: 0.0958 L1Reg: 0.0317 Total: 0.1275 \n",
            "Epoch [398], KL: 0.0861 L1Reg: 0.0312 Total: 0.1172 \n",
            "Epoch [399], KL: 0.0925 L1Reg: 0.0310 Total: 0.1235 \n",
            "Epoch [400], KL: 0.0801 L1Reg: 0.0307 Total: 0.1108 \n",
            "Epoch [401], KL: 0.0902 L1Reg: 0.0304 Total: 0.1206 \n",
            "Epoch [402], KL: 0.1147 L1Reg: 0.0304 Total: 0.1450 \n",
            "Epoch [403], KL: 0.0988 L1Reg: 0.0302 Total: 0.1290 \n",
            "Epoch [404], KL: 0.1339 L1Reg: 0.0300 Total: 0.1639 \n",
            "Epoch [405], KL: 0.0993 L1Reg: 0.0297 Total: 0.1291 \n",
            "Epoch [406], KL: 0.1021 L1Reg: 0.0296 Total: 0.1316 \n",
            "Epoch [407], KL: 0.0890 L1Reg: 0.0295 Total: 0.1186 \n",
            "Epoch [408], KL: 0.0847 L1Reg: 0.0291 Total: 0.1138 \n",
            "Epoch [409], KL: 0.0838 L1Reg: 0.0291 Total: 0.1129 \n",
            "Epoch [410], KL: 0.0796 L1Reg: 0.0285 Total: 0.1081 \n",
            "Epoch [411], KL: 0.0930 L1Reg: 0.0284 Total: 0.1214 \n",
            "Epoch [412], KL: 0.1050 L1Reg: 0.0288 Total: 0.1338 \n",
            "Epoch [413], KL: 0.0887 L1Reg: 0.0282 Total: 0.1168 \n",
            "Epoch [414], KL: 0.1141 L1Reg: 0.0283 Total: 0.1424 \n",
            "Epoch [415], KL: 0.0901 L1Reg: 0.0285 Total: 0.1186 \n",
            "Epoch [416], KL: 0.1148 L1Reg: 0.0280 Total: 0.1427 \n",
            "Epoch [417], KL: 0.1101 L1Reg: 0.0280 Total: 0.1380 \n",
            "Epoch [418], KL: 0.0960 L1Reg: 0.0286 Total: 0.1246 \n",
            "Epoch [419], KL: 0.0913 L1Reg: 0.0279 Total: 0.1191 \n",
            "Epoch [420], KL: 0.1045 L1Reg: 0.0276 Total: 0.1321 \n",
            "Epoch [421], KL: 0.0974 L1Reg: 0.0276 Total: 0.1250 \n",
            "Epoch [422], KL: 0.0948 L1Reg: 0.0272 Total: 0.1220 \n",
            "Epoch [423], KL: 0.0813 L1Reg: 0.0272 Total: 0.1085 \n",
            "Epoch [424], KL: 0.0790 L1Reg: 0.0268 Total: 0.1058 \n",
            "Epoch [425], KL: 0.0783 L1Reg: 0.0264 Total: 0.1047 \n",
            "Epoch [426], KL: 0.0846 L1Reg: 0.0261 Total: 0.1107 \n",
            "Epoch [427], KL: 0.0963 L1Reg: 0.0261 Total: 0.1224 \n",
            "Epoch [428], KL: 0.0973 L1Reg: 0.0259 Total: 0.1233 \n",
            "Epoch [429], KL: 0.1031 L1Reg: 0.0260 Total: 0.1291 \n",
            "Epoch [430], KL: 0.1109 L1Reg: 0.0262 Total: 0.1371 \n",
            "Epoch [431], KL: 0.1058 L1Reg: 0.0257 Total: 0.1316 \n",
            "Epoch [432], KL: 0.0859 L1Reg: 0.0254 Total: 0.1113 \n",
            "Epoch [433], KL: 0.0894 L1Reg: 0.0251 Total: 0.1145 \n",
            "Epoch [434], KL: 0.0831 L1Reg: 0.0249 Total: 0.1079 \n",
            "Epoch [435], KL: 0.0842 L1Reg: 0.0247 Total: 0.1089 \n",
            "Epoch [436], KL: 0.0900 L1Reg: 0.0246 Total: 0.1146 \n",
            "Epoch [437], KL: 0.0916 L1Reg: 0.0244 Total: 0.1161 \n",
            "Epoch [438], KL: 0.0758 L1Reg: 0.0245 Total: 0.1004 \n",
            "Epoch [439], KL: 0.0905 L1Reg: 0.0247 Total: 0.1152 \n",
            "Epoch [440], KL: 0.0873 L1Reg: 0.0243 Total: 0.1115 \n",
            "Epoch [441], KL: 0.0873 L1Reg: 0.0242 Total: 0.1115 \n",
            "Epoch [442], KL: 0.1400 L1Reg: 0.0250 Total: 0.1649 \n",
            "Epoch [443], KL: 0.1012 L1Reg: 0.0250 Total: 0.1262 \n",
            "Epoch [444], KL: 0.0956 L1Reg: 0.0244 Total: 0.1200 \n",
            "Epoch [445], KL: 0.0843 L1Reg: 0.0247 Total: 0.1090 \n",
            "Epoch [446], KL: 0.0969 L1Reg: 0.0241 Total: 0.1210 \n",
            "Epoch [447], KL: 0.0882 L1Reg: 0.0241 Total: 0.1123 \n",
            "Epoch [448], KL: 0.0924 L1Reg: 0.0240 Total: 0.1164 \n",
            "Epoch [449], KL: 0.0953 L1Reg: 0.0236 Total: 0.1189 \n",
            "Epoch [450], KL: 0.0894 L1Reg: 0.0233 Total: 0.1127 \n",
            "Epoch [451], KL: 0.0788 L1Reg: 0.0232 Total: 0.1020 \n",
            "Epoch [452], KL: 0.0741 L1Reg: 0.0230 Total: 0.0972 \n",
            "Epoch [453], KL: 0.0909 L1Reg: 0.0230 Total: 0.1139 \n",
            "Epoch [454], KL: 0.0751 L1Reg: 0.0227 Total: 0.0978 \n",
            "Epoch [455], KL: 0.1117 L1Reg: 0.0227 Total: 0.1344 \n",
            "Epoch [456], KL: 0.1087 L1Reg: 0.0226 Total: 0.1312 \n",
            "Epoch [457], KL: 0.1230 L1Reg: 0.0225 Total: 0.1456 \n",
            "Epoch [458], KL: 0.1123 L1Reg: 0.0221 Total: 0.1344 \n",
            "Epoch [459], KL: 0.1005 L1Reg: 0.0222 Total: 0.1227 \n",
            "Epoch [460], KL: 0.0955 L1Reg: 0.0221 Total: 0.1176 \n",
            "Epoch [461], KL: 0.0735 L1Reg: 0.0218 Total: 0.0953 \n",
            "Epoch [462], KL: 0.0832 L1Reg: 0.0218 Total: 0.1050 \n",
            "Epoch [463], KL: 0.0859 L1Reg: 0.0219 Total: 0.1079 \n",
            "Epoch [464], KL: 0.0790 L1Reg: 0.0217 Total: 0.1007 \n",
            "Epoch [465], KL: 0.0791 L1Reg: 0.0217 Total: 0.1008 \n",
            "Epoch [466], KL: 0.0818 L1Reg: 0.0216 Total: 0.1034 \n",
            "Epoch [467], KL: 0.0811 L1Reg: 0.0212 Total: 0.1023 \n",
            "Epoch [468], KL: 0.0893 L1Reg: 0.0218 Total: 0.1111 \n",
            "Epoch [469], KL: 0.1181 L1Reg: 0.0221 Total: 0.1402 \n",
            "Epoch [470], KL: 0.1022 L1Reg: 0.0216 Total: 0.1238 \n",
            "Epoch [471], KL: 0.0947 L1Reg: 0.0217 Total: 0.1164 \n",
            "Epoch [472], KL: 0.0825 L1Reg: 0.0216 Total: 0.1041 \n",
            "Epoch [473], KL: 0.0763 L1Reg: 0.0211 Total: 0.0974 \n",
            "Epoch [474], KL: 0.0999 L1Reg: 0.0207 Total: 0.1206 \n",
            "Epoch [475], KL: 0.0918 L1Reg: 0.0212 Total: 0.1130 \n",
            "Epoch [476], KL: 0.0940 L1Reg: 0.0208 Total: 0.1148 \n",
            "Epoch [477], KL: 0.0831 L1Reg: 0.0209 Total: 0.1039 \n",
            "Epoch [478], KL: 0.0741 L1Reg: 0.0205 Total: 0.0946 \n",
            "Epoch [479], KL: 0.0751 L1Reg: 0.0201 Total: 0.0952 \n",
            "Epoch [480], KL: 0.0859 L1Reg: 0.0199 Total: 0.1058 \n",
            "Epoch [481], KL: 0.1000 L1Reg: 0.0202 Total: 0.1202 \n",
            "Epoch [482], KL: 0.0985 L1Reg: 0.0201 Total: 0.1186 \n",
            "Epoch [483], KL: 0.1063 L1Reg: 0.0202 Total: 0.1265 \n",
            "Epoch [484], KL: 0.1069 L1Reg: 0.0204 Total: 0.1273 \n",
            "Epoch [485], KL: 0.0967 L1Reg: 0.0201 Total: 0.1168 \n",
            "Epoch [486], KL: 0.0797 L1Reg: 0.0198 Total: 0.0995 \n",
            "Epoch [487], KL: 0.0807 L1Reg: 0.0196 Total: 0.1004 \n",
            "Epoch [488], KL: 0.0850 L1Reg: 0.0193 Total: 0.1043 \n",
            "Epoch [489], KL: 0.0847 L1Reg: 0.0197 Total: 0.1043 \n",
            "Epoch [490], KL: 0.1062 L1Reg: 0.0196 Total: 0.1257 \n",
            "Epoch [491], KL: 0.0975 L1Reg: 0.0192 Total: 0.1167 \n",
            "Epoch [492], KL: 0.0757 L1Reg: 0.0191 Total: 0.0948 \n",
            "Epoch [493], KL: 0.0966 L1Reg: 0.0197 Total: 0.1163 \n",
            "Epoch [494], KL: 0.0891 L1Reg: 0.0200 Total: 0.1091 \n",
            "Epoch [495], KL: 0.1066 L1Reg: 0.0198 Total: 0.1264 \n",
            "Epoch [496], KL: 0.0882 L1Reg: 0.0203 Total: 0.1085 \n",
            "Epoch [497], KL: 0.0933 L1Reg: 0.0196 Total: 0.1129 \n",
            "Epoch [498], KL: 0.0967 L1Reg: 0.0193 Total: 0.1160 \n",
            "Epoch [499], KL: 0.0733 L1Reg: 0.0193 Total: 0.0926 \n",
            "Epoch [500], KL: 0.0810 L1Reg: 0.0188 Total: 0.0998 \n",
            "Epoch [501], KL: 0.0802 L1Reg: 0.0186 Total: 0.0988 \n",
            "Epoch [502], KL: 0.0853 L1Reg: 0.0188 Total: 0.1041 \n",
            "Epoch [503], KL: 0.0759 L1Reg: 0.0187 Total: 0.0946 \n",
            "Epoch [504], KL: 0.0905 L1Reg: 0.0181 Total: 0.1086 \n",
            "Epoch [505], KL: 0.0930 L1Reg: 0.0184 Total: 0.1114 \n",
            "Epoch [506], KL: 0.0814 L1Reg: 0.0182 Total: 0.0997 \n",
            "Epoch [507], KL: 0.0842 L1Reg: 0.0182 Total: 0.1024 \n",
            "Epoch [508], KL: 0.1048 L1Reg: 0.0184 Total: 0.1232 \n",
            "Epoch [509], KL: 0.0905 L1Reg: 0.0181 Total: 0.1086 \n",
            "Epoch [510], KL: 0.0845 L1Reg: 0.0178 Total: 0.1023 \n",
            "Epoch [511], KL: 0.1013 L1Reg: 0.0182 Total: 0.1195 \n",
            "Epoch [512], KL: 0.0980 L1Reg: 0.0180 Total: 0.1160 \n",
            "Epoch [513], KL: 0.0828 L1Reg: 0.0178 Total: 0.1005 \n",
            "Epoch [514], KL: 0.0867 L1Reg: 0.0177 Total: 0.1044 \n",
            "Epoch [515], KL: 0.0720 L1Reg: 0.0178 Total: 0.0898 \n",
            "Epoch [516], KL: 0.0770 L1Reg: 0.0179 Total: 0.0949 \n",
            "Epoch [517], KL: 0.0868 L1Reg: 0.0178 Total: 0.1046 \n",
            "Epoch [518], KL: 0.0841 L1Reg: 0.0177 Total: 0.1018 \n",
            "Epoch [519], KL: 0.0729 L1Reg: 0.0177 Total: 0.0906 \n",
            "Epoch [520], KL: 0.0879 L1Reg: 0.0181 Total: 0.1059 \n",
            "Epoch [521], KL: 0.0961 L1Reg: 0.0180 Total: 0.1141 \n",
            "Epoch [522], KL: 0.0853 L1Reg: 0.0178 Total: 0.1031 \n",
            "Epoch [523], KL: 0.0904 L1Reg: 0.0180 Total: 0.1084 \n",
            "Epoch [524], KL: 0.0872 L1Reg: 0.0178 Total: 0.1050 \n",
            "Epoch [525], KL: 0.0835 L1Reg: 0.0175 Total: 0.1010 \n",
            "Epoch [526], KL: 0.0732 L1Reg: 0.0173 Total: 0.0905 \n",
            "Epoch [527], KL: 0.0733 L1Reg: 0.0171 Total: 0.0904 \n",
            "Epoch [528], KL: 0.0865 L1Reg: 0.0168 Total: 0.1032 \n",
            "Epoch [529], KL: 0.0917 L1Reg: 0.0168 Total: 0.1085 \n",
            "Epoch [530], KL: 0.0968 L1Reg: 0.0168 Total: 0.1136 \n",
            "Epoch [531], KL: 0.0887 L1Reg: 0.0167 Total: 0.1054 \n",
            "Epoch [532], KL: 0.0780 L1Reg: 0.0168 Total: 0.0948 \n",
            "Epoch [533], KL: 0.0848 L1Reg: 0.0166 Total: 0.1014 \n",
            "Epoch [534], KL: 0.1054 L1Reg: 0.0168 Total: 0.1221 \n",
            "Epoch [535], KL: 0.0788 L1Reg: 0.0172 Total: 0.0960 \n",
            "Epoch [536], KL: 0.0919 L1Reg: 0.0168 Total: 0.1088 \n",
            "Epoch [537], KL: 0.0879 L1Reg: 0.0166 Total: 0.1045 \n",
            "Epoch [538], KL: 0.0853 L1Reg: 0.0167 Total: 0.1020 \n",
            "Epoch [539], KL: 0.0977 L1Reg: 0.0165 Total: 0.1142 \n",
            "Epoch [540], KL: 0.0825 L1Reg: 0.0162 Total: 0.0987 \n",
            "Epoch [541], KL: 0.0758 L1Reg: 0.0163 Total: 0.0921 \n",
            "Epoch [542], KL: 0.0748 L1Reg: 0.0163 Total: 0.0911 \n",
            "Epoch [543], KL: 0.0734 L1Reg: 0.0161 Total: 0.0895 \n",
            "Epoch [544], KL: 0.0768 L1Reg: 0.0162 Total: 0.0930 \n",
            "Epoch [545], KL: 0.0720 L1Reg: 0.0169 Total: 0.0888 \n",
            "Epoch [546], KL: 0.0805 L1Reg: 0.0169 Total: 0.0974 \n",
            "Epoch [547], KL: 0.0805 L1Reg: 0.0172 Total: 0.0976 \n",
            "Epoch [548], KL: 0.0746 L1Reg: 0.0168 Total: 0.0915 \n",
            "Epoch [549], KL: 0.0910 L1Reg: 0.0167 Total: 0.1076 \n",
            "Epoch [550], KL: 0.0803 L1Reg: 0.0167 Total: 0.0970 \n",
            "Epoch [551], KL: 0.0784 L1Reg: 0.0161 Total: 0.0945 \n",
            "Epoch [552], KL: 0.0790 L1Reg: 0.0161 Total: 0.0951 \n",
            "Epoch [553], KL: 0.0982 L1Reg: 0.0164 Total: 0.1145 \n",
            "Epoch [554], KL: 0.0756 L1Reg: 0.0164 Total: 0.0920 \n",
            "Epoch [555], KL: 0.0847 L1Reg: 0.0159 Total: 0.1006 \n",
            "Epoch [556], KL: 0.0913 L1Reg: 0.0157 Total: 0.1071 \n",
            "Epoch [557], KL: 0.0910 L1Reg: 0.0159 Total: 0.1069 \n",
            "Epoch [558], KL: 0.1023 L1Reg: 0.0156 Total: 0.1179 \n",
            "Epoch [559], KL: 0.0834 L1Reg: 0.0155 Total: 0.0989 \n",
            "Epoch [560], KL: 0.1084 L1Reg: 0.0155 Total: 0.1240 \n",
            "Epoch [561], KL: 0.0880 L1Reg: 0.0153 Total: 0.1034 \n",
            "Epoch [562], KL: 0.0796 L1Reg: 0.0158 Total: 0.0955 \n",
            "Epoch [563], KL: 0.0757 L1Reg: 0.0154 Total: 0.0911 \n",
            "Epoch [564], KL: 0.0884 L1Reg: 0.0154 Total: 0.1038 \n",
            "Epoch [565], KL: 0.0950 L1Reg: 0.0156 Total: 0.1105 \n",
            "Epoch [566], KL: 0.0922 L1Reg: 0.0154 Total: 0.1077 \n",
            "Epoch [567], KL: 0.0966 L1Reg: 0.0154 Total: 0.1119 \n",
            "Epoch [568], KL: 0.0870 L1Reg: 0.0158 Total: 0.1028 \n",
            "Epoch [569], KL: 0.0852 L1Reg: 0.0153 Total: 0.1005 \n",
            "Epoch [570], KL: 0.0673 L1Reg: 0.0159 Total: 0.0832 \n",
            "Epoch [571], KL: 0.0721 L1Reg: 0.0159 Total: 0.0880 \n",
            "Epoch [572], KL: 0.0880 L1Reg: 0.0158 Total: 0.1038 \n",
            "Epoch [573], KL: 0.0782 L1Reg: 0.0158 Total: 0.0940 \n",
            "Epoch [574], KL: 0.0704 L1Reg: 0.0158 Total: 0.0862 \n",
            "Epoch [575], KL: 0.0747 L1Reg: 0.0155 Total: 0.0902 \n",
            "Epoch [576], KL: 0.0694 L1Reg: 0.0153 Total: 0.0846 \n",
            "Epoch [577], KL: 0.0773 L1Reg: 0.0153 Total: 0.0926 \n",
            "Epoch [578], KL: 0.0792 L1Reg: 0.0155 Total: 0.0947 \n",
            "Epoch [579], KL: 0.0798 L1Reg: 0.0154 Total: 0.0951 \n",
            "Epoch [580], KL: 0.0779 L1Reg: 0.0150 Total: 0.0929 \n",
            "Epoch [581], KL: 0.0810 L1Reg: 0.0146 Total: 0.0956 \n",
            "Epoch [582], KL: 0.0786 L1Reg: 0.0159 Total: 0.0945 \n",
            "Epoch [583], KL: 0.0949 L1Reg: 0.0157 Total: 0.1106 \n",
            "Epoch [584], KL: 0.1055 L1Reg: 0.0157 Total: 0.1212 \n",
            "Epoch [585], KL: 0.0947 L1Reg: 0.0155 Total: 0.1102 \n",
            "Epoch [586], KL: 0.0971 L1Reg: 0.0154 Total: 0.1125 \n",
            "Epoch [587], KL: 0.0896 L1Reg: 0.0150 Total: 0.1046 \n",
            "Epoch [588], KL: 0.1131 L1Reg: 0.0148 Total: 0.1278 \n",
            "Epoch [589], KL: 0.0856 L1Reg: 0.0150 Total: 0.1006 \n",
            "Epoch [590], KL: 0.0780 L1Reg: 0.0153 Total: 0.0933 \n",
            "Epoch [591], KL: 0.0813 L1Reg: 0.0155 Total: 0.0967 \n",
            "Epoch [592], KL: 0.0800 L1Reg: 0.0153 Total: 0.0953 \n",
            "Epoch [593], KL: 0.0905 L1Reg: 0.0155 Total: 0.1061 \n",
            "Epoch [594], KL: 0.0813 L1Reg: 0.0157 Total: 0.0970 \n",
            "Epoch [595], KL: 0.0952 L1Reg: 0.0154 Total: 0.1106 \n",
            "Epoch [596], KL: 0.0821 L1Reg: 0.0150 Total: 0.0971 \n",
            "Epoch [597], KL: 0.0722 L1Reg: 0.0150 Total: 0.0872 \n",
            "Epoch [598], KL: 0.0761 L1Reg: 0.0150 Total: 0.0911 \n",
            "Epoch [599], KL: 0.0881 L1Reg: 0.0150 Total: 0.1031 \n",
            "Epoch [600], KL: 0.0662 L1Reg: 0.0161 Total: 0.0824 \n",
            "Epoch [601], KL: 0.0638 L1Reg: 0.0157 Total: 0.0795 \n",
            "Epoch [602], KL: 0.0678 L1Reg: 0.0152 Total: 0.0830 \n",
            "Epoch [603], KL: 0.0764 L1Reg: 0.0155 Total: 0.0919 \n",
            "Epoch [604], KL: 0.0834 L1Reg: 0.0151 Total: 0.0985 \n",
            "Epoch [605], KL: 0.0725 L1Reg: 0.0146 Total: 0.0871 \n",
            "Epoch [606], KL: 0.0842 L1Reg: 0.0147 Total: 0.0988 \n",
            "Epoch [607], KL: 0.0890 L1Reg: 0.0148 Total: 0.1037 \n",
            "Epoch [608], KL: 0.0876 L1Reg: 0.0154 Total: 0.1030 \n",
            "Epoch [609], KL: 0.1102 L1Reg: 0.0153 Total: 0.1255 \n",
            "Epoch [610], KL: 0.1058 L1Reg: 0.0149 Total: 0.1207 \n",
            "Epoch [611], KL: 0.0963 L1Reg: 0.0147 Total: 0.1110 \n",
            "Epoch [612], KL: 0.0967 L1Reg: 0.0147 Total: 0.1114 \n",
            "Epoch [613], KL: 0.0876 L1Reg: 0.0150 Total: 0.1025 \n",
            "Epoch [614], KL: 0.0824 L1Reg: 0.0152 Total: 0.0976 \n",
            "Epoch [615], KL: 0.0787 L1Reg: 0.0153 Total: 0.0940 \n",
            "Epoch [616], KL: 0.0815 L1Reg: 0.0154 Total: 0.0969 \n",
            "Epoch [617], KL: 0.0833 L1Reg: 0.0148 Total: 0.0981 \n",
            "Epoch [618], KL: 0.0804 L1Reg: 0.0146 Total: 0.0950 \n",
            "Epoch [619], KL: 0.0806 L1Reg: 0.0151 Total: 0.0958 \n",
            "Epoch [620], KL: 0.0934 L1Reg: 0.0146 Total: 0.1080 \n",
            "Epoch [621], KL: 0.0922 L1Reg: 0.0145 Total: 0.1067 \n",
            "Epoch [622], KL: 0.0804 L1Reg: 0.0142 Total: 0.0947 \n",
            "Epoch [623], KL: 0.0796 L1Reg: 0.0146 Total: 0.0942 \n",
            "Epoch [624], KL: 0.0771 L1Reg: 0.0145 Total: 0.0916 \n",
            "Epoch [625], KL: 0.0744 L1Reg: 0.0145 Total: 0.0888 \n",
            "Epoch [626], KL: 0.0589 L1Reg: 0.0147 Total: 0.0737 \n",
            "Epoch [627], KL: 0.0708 L1Reg: 0.0145 Total: 0.0854 \n",
            "Epoch [628], KL: 0.0677 L1Reg: 0.0145 Total: 0.0822 \n",
            "Epoch [629], KL: 0.0781 L1Reg: 0.0143 Total: 0.0924 \n",
            "Epoch [630], KL: 0.0876 L1Reg: 0.0143 Total: 0.1019 \n",
            "Epoch [631], KL: 0.0919 L1Reg: 0.0150 Total: 0.1068 \n",
            "Epoch [632], KL: 0.0732 L1Reg: 0.0147 Total: 0.0879 \n",
            "Epoch [633], KL: 0.0850 L1Reg: 0.0141 Total: 0.0991 \n",
            "Epoch [634], KL: 0.0792 L1Reg: 0.0141 Total: 0.0933 \n",
            "Epoch [635], KL: 0.0943 L1Reg: 0.0137 Total: 0.1081 \n",
            "Epoch [636], KL: 0.1042 L1Reg: 0.0146 Total: 0.1188 \n",
            "Epoch [637], KL: 0.0942 L1Reg: 0.0154 Total: 0.1096 \n",
            "Epoch [638], KL: 0.1090 L1Reg: 0.0151 Total: 0.1241 \n",
            "Epoch [639], KL: 0.1049 L1Reg: 0.0146 Total: 0.1195 \n",
            "Epoch [640], KL: 0.0941 L1Reg: 0.0143 Total: 0.1084 \n",
            "Epoch [641], KL: 0.0842 L1Reg: 0.0140 Total: 0.0982 \n",
            "Epoch [642], KL: 0.0753 L1Reg: 0.0144 Total: 0.0897 \n",
            "Epoch [643], KL: 0.0824 L1Reg: 0.0147 Total: 0.0972 \n",
            "Epoch [644], KL: 0.0947 L1Reg: 0.0146 Total: 0.1092 \n",
            "Epoch [645], KL: 0.0836 L1Reg: 0.0145 Total: 0.0981 \n",
            "Epoch [646], KL: 0.0811 L1Reg: 0.0148 Total: 0.0959 \n",
            "Epoch [647], KL: 0.0884 L1Reg: 0.0147 Total: 0.1031 \n",
            "Epoch [648], KL: 0.0861 L1Reg: 0.0145 Total: 0.1006 \n",
            "Epoch [649], KL: 0.0791 L1Reg: 0.0143 Total: 0.0934 \n",
            "Epoch [650], KL: 0.0804 L1Reg: 0.0140 Total: 0.0944 \n",
            "Epoch [651], KL: 0.0799 L1Reg: 0.0139 Total: 0.0939 \n",
            "Epoch [652], KL: 0.0818 L1Reg: 0.0140 Total: 0.0958 \n",
            "Epoch [653], KL: 0.0825 L1Reg: 0.0138 Total: 0.0963 \n",
            "Epoch [654], KL: 0.0748 L1Reg: 0.0146 Total: 0.0894 \n",
            "Epoch [655], KL: 0.0772 L1Reg: 0.0144 Total: 0.0916 \n",
            "Epoch [656], KL: 0.0763 L1Reg: 0.0141 Total: 0.0904 \n",
            "Epoch [657], KL: 0.0859 L1Reg: 0.0140 Total: 0.0999 \n",
            "Epoch [658], KL: 0.0908 L1Reg: 0.0138 Total: 0.1046 \n",
            "Epoch [659], KL: 0.0875 L1Reg: 0.0139 Total: 0.1013 \n",
            "Epoch [660], KL: 0.0901 L1Reg: 0.0138 Total: 0.1039 \n",
            "Epoch [661], KL: 0.0862 L1Reg: 0.0163 Total: 0.1025 \n",
            "Epoch [662], KL: 0.0806 L1Reg: 0.0154 Total: 0.0960 \n",
            "Epoch [663], KL: 0.1038 L1Reg: 0.0149 Total: 0.1187 \n",
            "Epoch [664], KL: 0.1089 L1Reg: 0.0147 Total: 0.1236 \n",
            "Epoch [665], KL: 0.1119 L1Reg: 0.0142 Total: 0.1261 \n",
            "Epoch [666], KL: 0.1174 L1Reg: 0.0141 Total: 0.1314 \n",
            "Epoch [667], KL: 0.0797 L1Reg: 0.0139 Total: 0.0936 \n",
            "Epoch [668], KL: 0.0835 L1Reg: 0.0145 Total: 0.0980 \n",
            "Epoch [669], KL: 0.1007 L1Reg: 0.0148 Total: 0.1155 \n",
            "Epoch [670], KL: 0.0912 L1Reg: 0.0145 Total: 0.1057 \n",
            "Epoch [671], KL: 0.0938 L1Reg: 0.0142 Total: 0.1080 \n",
            "Epoch [672], KL: 0.0998 L1Reg: 0.0140 Total: 0.1138 \n",
            "Epoch [673], KL: 0.0961 L1Reg: 0.0139 Total: 0.1100 \n",
            "Epoch [674], KL: 0.0925 L1Reg: 0.0137 Total: 0.1061 \n",
            "Epoch [675], KL: 0.0945 L1Reg: 0.0135 Total: 0.1079 \n",
            "Epoch [676], KL: 0.0968 L1Reg: 0.0133 Total: 0.1101 \n",
            "Epoch [677], KL: 0.1009 L1Reg: 0.0144 Total: 0.1153 \n",
            "Epoch [678], KL: 0.0667 L1Reg: 0.0138 Total: 0.0805 \n",
            "Epoch [679], KL: 0.0720 L1Reg: 0.0137 Total: 0.0857 \n",
            "Epoch [680], KL: 0.0828 L1Reg: 0.0138 Total: 0.0966 \n",
            "Epoch [681], KL: 0.0813 L1Reg: 0.0137 Total: 0.0950 \n",
            "Epoch [682], KL: 0.0831 L1Reg: 0.0137 Total: 0.0968 \n",
            "Epoch [683], KL: 0.0777 L1Reg: 0.0133 Total: 0.0911 \n",
            "Epoch [684], KL: 0.0875 L1Reg: 0.0138 Total: 0.1014 \n",
            "Epoch [685], KL: 0.0876 L1Reg: 0.0150 Total: 0.1026 \n",
            "Epoch [686], KL: 0.0934 L1Reg: 0.0144 Total: 0.1078 \n",
            "Epoch [687], KL: 0.1090 L1Reg: 0.0137 Total: 0.1227 \n",
            "Epoch [688], KL: 0.0920 L1Reg: 0.0134 Total: 0.1054 \n",
            "Epoch [689], KL: 0.0982 L1Reg: 0.0133 Total: 0.1115 \n",
            "Epoch [690], KL: 0.1241 L1Reg: 0.0135 Total: 0.1376 \n",
            "Epoch [691], KL: 0.1106 L1Reg: 0.0136 Total: 0.1242 \n",
            "Epoch [692], KL: 0.1115 L1Reg: 0.0135 Total: 0.1250 \n",
            "Epoch [693], KL: 0.1273 L1Reg: 0.0153 Total: 0.1426 \n",
            "Epoch [694], KL: 0.1058 L1Reg: 0.0147 Total: 0.1204 \n",
            "Epoch [695], KL: 0.0971 L1Reg: 0.0142 Total: 0.1113 \n",
            "Epoch [696], KL: 0.0889 L1Reg: 0.0136 Total: 0.1025 \n",
            "Epoch [697], KL: 0.0898 L1Reg: 0.0138 Total: 0.1036 \n",
            "Epoch [698], KL: 0.0896 L1Reg: 0.0137 Total: 0.1034 \n",
            "Epoch [699], KL: 0.0911 L1Reg: 0.0138 Total: 0.1049 \n",
            "Epoch [700], KL: 0.0980 L1Reg: 0.0139 Total: 0.1119 \n",
            "Epoch [701], KL: 0.1015 L1Reg: 0.0135 Total: 0.1151 \n",
            "Epoch [702], KL: 0.0997 L1Reg: 0.0132 Total: 0.1129 \n",
            "Epoch [703], KL: 0.1046 L1Reg: 0.0131 Total: 0.1177 \n",
            "Epoch [704], KL: 0.0968 L1Reg: 0.0128 Total: 0.1096 \n",
            "Epoch [705], KL: 0.0802 L1Reg: 0.0128 Total: 0.0930 \n",
            "Epoch [706], KL: 0.0790 L1Reg: 0.0134 Total: 0.0924 \n",
            "Epoch [707], KL: 0.0831 L1Reg: 0.0132 Total: 0.0963 \n",
            "Epoch [708], KL: 0.0768 L1Reg: 0.0134 Total: 0.0902 \n",
            "Epoch [709], KL: 0.0805 L1Reg: 0.0132 Total: 0.0937 \n",
            "Epoch [710], KL: 0.0905 L1Reg: 0.0126 Total: 0.1031 \n",
            "Epoch [711], KL: 0.0923 L1Reg: 0.0128 Total: 0.1051 \n",
            "Epoch [712], KL: 0.1017 L1Reg: 0.0130 Total: 0.1146 \n",
            "Epoch [713], KL: 0.0868 L1Reg: 0.0127 Total: 0.0994 \n",
            "Epoch [714], KL: 0.1031 L1Reg: 0.0127 Total: 0.1159 \n",
            "Epoch [715], KL: 0.1146 L1Reg: 0.0149 Total: 0.1296 \n",
            "Epoch [716], KL: 0.1178 L1Reg: 0.0145 Total: 0.1323 \n",
            "Epoch [717], KL: 0.1232 L1Reg: 0.0139 Total: 0.1371 \n",
            "Epoch [718], KL: 0.1139 L1Reg: 0.0137 Total: 0.1277 \n",
            "Epoch [719], KL: 0.1080 L1Reg: 0.0135 Total: 0.1215 \n",
            "Epoch [720], KL: 0.0993 L1Reg: 0.0131 Total: 0.1124 \n",
            "Epoch [721], KL: 0.1104 L1Reg: 0.0132 Total: 0.1236 \n",
            "Epoch [722], KL: 0.0921 L1Reg: 0.0132 Total: 0.1052 \n",
            "Epoch [723], KL: 0.0802 L1Reg: 0.0134 Total: 0.0935 \n",
            "Epoch [724], KL: 0.0871 L1Reg: 0.0131 Total: 0.1002 \n",
            "Epoch [725], KL: 0.0888 L1Reg: 0.0126 Total: 0.1014 \n",
            "Epoch [726], KL: 0.1056 L1Reg: 0.0125 Total: 0.1182 \n",
            "Epoch [727], KL: 0.0924 L1Reg: 0.0129 Total: 0.1053 \n",
            "Epoch [728], KL: 0.1032 L1Reg: 0.0128 Total: 0.1160 \n",
            "Epoch [729], KL: 0.1118 L1Reg: 0.0129 Total: 0.1246 \n",
            "Epoch [730], KL: 0.0973 L1Reg: 0.0128 Total: 0.1101 \n",
            "Epoch [731], KL: 0.0941 L1Reg: 0.0129 Total: 0.1070 \n",
            "Epoch [732], KL: 0.0775 L1Reg: 0.0126 Total: 0.0901 \n",
            "Epoch [733], KL: 0.0881 L1Reg: 0.0127 Total: 0.1008 \n",
            "Epoch [734], KL: 0.0879 L1Reg: 0.0127 Total: 0.1006 \n",
            "Epoch [735], KL: 0.0916 L1Reg: 0.0128 Total: 0.1044 \n",
            "Epoch [736], KL: 0.1029 L1Reg: 0.0131 Total: 0.1160 \n",
            "Epoch [737], KL: 0.1011 L1Reg: 0.0124 Total: 0.1135 \n",
            "Epoch [738], KL: 0.0852 L1Reg: 0.0128 Total: 0.0979 \n",
            "Epoch [739], KL: 0.1064 L1Reg: 0.0133 Total: 0.1197 \n",
            "Epoch [740], KL: 0.0916 L1Reg: 0.0130 Total: 0.1045 \n",
            "Epoch [741], KL: 0.1005 L1Reg: 0.0125 Total: 0.1130 \n",
            "Epoch [742], KL: 0.1231 L1Reg: 0.0126 Total: 0.1357 \n",
            "Epoch [743], KL: 0.1033 L1Reg: 0.0121 Total: 0.1154 \n",
            "Epoch [744], KL: 0.1179 L1Reg: 0.0121 Total: 0.1300 \n",
            "Epoch [745], KL: 0.1169 L1Reg: 0.0153 Total: 0.1321 \n",
            "Epoch [746], KL: 0.1165 L1Reg: 0.0142 Total: 0.1307 \n",
            "Epoch [747], KL: 0.1030 L1Reg: 0.0145 Total: 0.1175 \n",
            "Epoch [748], KL: 0.0936 L1Reg: 0.0138 Total: 0.1074 \n",
            "Epoch [749], KL: 0.0991 L1Reg: 0.0134 Total: 0.1125 \n",
            "Epoch [750], KL: 0.0944 L1Reg: 0.0127 Total: 0.1071 \n",
            "Epoch [751], KL: 0.0944 L1Reg: 0.0125 Total: 0.1069 \n",
            "Epoch [752], KL: 0.0950 L1Reg: 0.0124 Total: 0.1074 \n",
            "Epoch [753], KL: 0.0972 L1Reg: 0.0129 Total: 0.1101 \n",
            "Epoch [754], KL: 0.1048 L1Reg: 0.0126 Total: 0.1173 \n",
            "Epoch [755], KL: 0.1277 L1Reg: 0.0136 Total: 0.1414 \n",
            "Epoch [756], KL: 0.1006 L1Reg: 0.0127 Total: 0.1133 \n",
            "Epoch [757], KL: 0.0972 L1Reg: 0.0129 Total: 0.1101 \n",
            "Epoch [758], KL: 0.0840 L1Reg: 0.0124 Total: 0.0963 \n",
            "Epoch [759], KL: 0.0909 L1Reg: 0.0123 Total: 0.1032 \n",
            "Epoch [760], KL: 0.0899 L1Reg: 0.0122 Total: 0.1022 \n",
            "Epoch [761], KL: 0.0982 L1Reg: 0.0118 Total: 0.1100 \n",
            "Epoch [762], KL: 0.0805 L1Reg: 0.0135 Total: 0.0940 \n",
            "Epoch [763], KL: 0.1117 L1Reg: 0.0126 Total: 0.1243 \n",
            "Epoch [764], KL: 0.0845 L1Reg: 0.0122 Total: 0.0967 \n",
            "Epoch [765], KL: 0.1037 L1Reg: 0.0122 Total: 0.1159 \n",
            "Epoch [766], KL: 0.1012 L1Reg: 0.0119 Total: 0.1132 \n",
            "Epoch [767], KL: 0.1084 L1Reg: 0.0118 Total: 0.1202 \n",
            "Epoch [768], KL: 0.1258 L1Reg: 0.0122 Total: 0.1380 \n",
            "Epoch [769], KL: 0.1111 L1Reg: 0.0130 Total: 0.1240 \n",
            "Epoch [770], KL: 0.1051 L1Reg: 0.0126 Total: 0.1177 \n",
            "Epoch [771], KL: 0.1219 L1Reg: 0.0135 Total: 0.1354 \n",
            "Epoch [772], KL: 0.1070 L1Reg: 0.0130 Total: 0.1200 \n",
            "Epoch [773], KL: 0.1041 L1Reg: 0.0125 Total: 0.1166 \n",
            "Epoch [774], KL: 0.0936 L1Reg: 0.0120 Total: 0.1056 \n",
            "Epoch [775], KL: 0.0958 L1Reg: 0.0119 Total: 0.1078 \n",
            "Epoch [776], KL: 0.0952 L1Reg: 0.0117 Total: 0.1070 \n",
            "Epoch [777], KL: 0.1022 L1Reg: 0.0139 Total: 0.1160 \n",
            "Epoch [778], KL: 0.0992 L1Reg: 0.0133 Total: 0.1125 \n",
            "Epoch [779], KL: 0.0957 L1Reg: 0.0131 Total: 0.1087 \n",
            "Epoch [780], KL: 0.1001 L1Reg: 0.0123 Total: 0.1125 \n",
            "Epoch [781], KL: 0.1150 L1Reg: 0.0124 Total: 0.1274 \n",
            "Epoch [782], KL: 0.1206 L1Reg: 0.0119 Total: 0.1325 \n",
            "Epoch [783], KL: 0.1100 L1Reg: 0.0116 Total: 0.1216 \n",
            "Epoch [784], KL: 0.1079 L1Reg: 0.0119 Total: 0.1198 \n",
            "Epoch [785], KL: 0.1097 L1Reg: 0.0127 Total: 0.1225 \n",
            "Epoch [786], KL: 0.0826 L1Reg: 0.0126 Total: 0.0952 \n",
            "Epoch [787], KL: 0.0827 L1Reg: 0.0121 Total: 0.0948 \n",
            "Epoch [788], KL: 0.1098 L1Reg: 0.0118 Total: 0.1216 \n",
            "Epoch [789], KL: 0.1078 L1Reg: 0.0115 Total: 0.1193 \n",
            "Epoch [790], KL: 0.0936 L1Reg: 0.0114 Total: 0.1050 \n",
            "Epoch [791], KL: 0.0981 L1Reg: 0.0114 Total: 0.1095 \n",
            "Epoch [792], KL: 0.1374 L1Reg: 0.0131 Total: 0.1505 \n",
            "Epoch [793], KL: 0.1191 L1Reg: 0.0142 Total: 0.1332 \n",
            "Epoch [794], KL: 0.1158 L1Reg: 0.0133 Total: 0.1291 \n",
            "Epoch [795], KL: 0.1220 L1Reg: 0.0125 Total: 0.1346 \n",
            "Epoch [796], KL: 0.0929 L1Reg: 0.0124 Total: 0.1053 \n",
            "Epoch [797], KL: 0.0914 L1Reg: 0.0123 Total: 0.1036 \n",
            "Epoch [798], KL: 0.1077 L1Reg: 0.0121 Total: 0.1198 \n",
            "Epoch [799], KL: 0.0984 L1Reg: 0.0118 Total: 0.1102 \n",
            "Epoch [800], KL: 0.0984 L1Reg: 0.0121 Total: 0.1104 \n",
            "Epoch [801], KL: 0.0948 L1Reg: 0.0121 Total: 0.1069 \n",
            "Epoch [802], KL: 0.1032 L1Reg: 0.0117 Total: 0.1150 \n",
            "Epoch [803], KL: 0.1052 L1Reg: 0.0115 Total: 0.1167 \n",
            "Epoch [804], KL: 0.0848 L1Reg: 0.0119 Total: 0.0967 \n",
            "Epoch [805], KL: 0.0898 L1Reg: 0.0118 Total: 0.1016 \n",
            "Epoch [806], KL: 0.1127 L1Reg: 0.0113 Total: 0.1240 \n",
            "Epoch [807], KL: 0.1300 L1Reg: 0.0116 Total: 0.1416 \n",
            "Epoch [808], KL: 0.1132 L1Reg: 0.0120 Total: 0.1251 \n",
            "Epoch [809], KL: 0.1148 L1Reg: 0.0130 Total: 0.1277 \n",
            "Epoch [810], KL: 0.1078 L1Reg: 0.0121 Total: 0.1199 \n",
            "Epoch [811], KL: 0.1100 L1Reg: 0.0118 Total: 0.1219 \n",
            "Epoch [812], KL: 0.1250 L1Reg: 0.0118 Total: 0.1368 \n",
            "Epoch [813], KL: 0.1063 L1Reg: 0.0118 Total: 0.1180 \n",
            "Epoch [814], KL: 0.0944 L1Reg: 0.0119 Total: 0.1063 \n",
            "Epoch [815], KL: 0.0925 L1Reg: 0.0118 Total: 0.1043 \n",
            "Epoch [816], KL: 0.0934 L1Reg: 0.0120 Total: 0.1054 \n",
            "Epoch [817], KL: 0.0968 L1Reg: 0.0117 Total: 0.1085 \n",
            "Epoch [818], KL: 0.1066 L1Reg: 0.0121 Total: 0.1187 \n",
            "Epoch [819], KL: 0.1212 L1Reg: 0.0119 Total: 0.1331 \n",
            "Epoch [820], KL: 0.1251 L1Reg: 0.0118 Total: 0.1369 \n",
            "Epoch [821], KL: 0.1100 L1Reg: 0.0112 Total: 0.1212 \n",
            "Epoch [822], KL: 0.1063 L1Reg: 0.0114 Total: 0.1177 \n",
            "Epoch [823], KL: 0.1105 L1Reg: 0.0140 Total: 0.1244 \n",
            "Epoch [824], KL: 0.1055 L1Reg: 0.0134 Total: 0.1190 \n",
            "Epoch [825], KL: 0.1068 L1Reg: 0.0129 Total: 0.1197 \n",
            "Epoch [826], KL: 0.1118 L1Reg: 0.0125 Total: 0.1242 \n",
            "Epoch [827], KL: 0.1337 L1Reg: 0.0138 Total: 0.1475 \n",
            "Epoch [828], KL: 0.1133 L1Reg: 0.0129 Total: 0.1261 \n",
            "Epoch [829], KL: 0.1135 L1Reg: 0.0122 Total: 0.1257 \n",
            "Epoch [830], KL: 0.1009 L1Reg: 0.0119 Total: 0.1127 \n",
            "Epoch [831], KL: 0.0991 L1Reg: 0.0117 Total: 0.1109 \n",
            "Epoch [832], KL: 0.0968 L1Reg: 0.0120 Total: 0.1088 \n",
            "Epoch [833], KL: 0.1287 L1Reg: 0.0117 Total: 0.1404 \n",
            "Epoch [834], KL: 0.1280 L1Reg: 0.0110 Total: 0.1390 \n",
            "Epoch [835], KL: 0.1136 L1Reg: 0.0113 Total: 0.1250 \n",
            "Epoch [836], KL: 0.1111 L1Reg: 0.0117 Total: 0.1229 \n",
            "Epoch [837], KL: 0.1206 L1Reg: 0.0125 Total: 0.1332 \n",
            "Epoch [838], KL: 0.1093 L1Reg: 0.0126 Total: 0.1219 \n",
            "Epoch [839], KL: 0.0984 L1Reg: 0.0122 Total: 0.1106 \n",
            "Epoch [840], KL: 0.0977 L1Reg: 0.0116 Total: 0.1093 \n",
            "Epoch [841], KL: 0.0935 L1Reg: 0.0113 Total: 0.1049 \n",
            "Epoch [842], KL: 0.1030 L1Reg: 0.0111 Total: 0.1141 \n",
            "Epoch [843], KL: 0.0899 L1Reg: 0.0112 Total: 0.1011 \n",
            "Epoch [844], KL: 0.1129 L1Reg: 0.0113 Total: 0.1242 \n",
            "Epoch [845], KL: 0.1226 L1Reg: 0.0112 Total: 0.1338 \n",
            "Epoch [846], KL: 0.1109 L1Reg: 0.0121 Total: 0.1231 \n",
            "Epoch [847], KL: 0.1195 L1Reg: 0.0145 Total: 0.1339 \n",
            "Epoch [848], KL: 0.0894 L1Reg: 0.0136 Total: 0.1031 \n",
            "Epoch [849], KL: 0.0827 L1Reg: 0.0134 Total: 0.0961 \n",
            "Epoch [850], KL: 0.1000 L1Reg: 0.0129 Total: 0.1129 \n",
            "Epoch [851], KL: 0.0933 L1Reg: 0.0122 Total: 0.1054 \n",
            "Epoch [852], KL: 0.1284 L1Reg: 0.0118 Total: 0.1402 \n",
            "Epoch [853], KL: 0.1012 L1Reg: 0.0118 Total: 0.1130 \n",
            "Epoch [854], KL: 0.1172 L1Reg: 0.0118 Total: 0.1290 \n",
            "Epoch [855], KL: 0.1171 L1Reg: 0.0115 Total: 0.1286 \n",
            "Epoch [856], KL: 0.1201 L1Reg: 0.0114 Total: 0.1315 \n",
            "Epoch [857], KL: 0.1116 L1Reg: 0.0109 Total: 0.1225 \n",
            "Epoch [858], KL: 0.1054 L1Reg: 0.0107 Total: 0.1162 \n",
            "Epoch [859], KL: 0.1228 L1Reg: 0.0109 Total: 0.1337 \n",
            "Epoch [860], KL: 0.1304 L1Reg: 0.0136 Total: 0.1440 \n",
            "Epoch [861], KL: 0.1364 L1Reg: 0.0130 Total: 0.1494 \n",
            "Epoch [862], KL: 0.1129 L1Reg: 0.0125 Total: 0.1255 \n",
            "Epoch [863], KL: 0.1298 L1Reg: 0.0121 Total: 0.1419 \n",
            "Epoch [864], KL: 0.1101 L1Reg: 0.0114 Total: 0.1215 \n",
            "Epoch [865], KL: 0.1065 L1Reg: 0.0112 Total: 0.1178 \n",
            "Epoch [866], KL: 0.1022 L1Reg: 0.0111 Total: 0.1133 \n",
            "Epoch [867], KL: 0.1125 L1Reg: 0.0110 Total: 0.1235 \n",
            "Epoch [868], KL: 0.1111 L1Reg: 0.0109 Total: 0.1221 \n",
            "Epoch [869], KL: 0.0929 L1Reg: 0.0108 Total: 0.1037 \n",
            "Epoch [870], KL: 0.1180 L1Reg: 0.0135 Total: 0.1315 \n",
            "Epoch [871], KL: 0.1090 L1Reg: 0.0129 Total: 0.1219 \n",
            "Epoch [872], KL: 0.1103 L1Reg: 0.0126 Total: 0.1229 \n",
            "Epoch [873], KL: 0.1065 L1Reg: 0.0123 Total: 0.1188 \n",
            "Epoch [874], KL: 0.0932 L1Reg: 0.0117 Total: 0.1048 \n",
            "Epoch [875], KL: 0.1127 L1Reg: 0.0118 Total: 0.1244 \n",
            "Epoch [876], KL: 0.0805 L1Reg: 0.0112 Total: 0.0916 \n",
            "Epoch [877], KL: 0.0968 L1Reg: 0.0113 Total: 0.1081 \n",
            "Epoch [878], KL: 0.1029 L1Reg: 0.0120 Total: 0.1149 \n",
            "Epoch [879], KL: 0.1268 L1Reg: 0.0112 Total: 0.1380 \n",
            "Epoch [880], KL: 0.1317 L1Reg: 0.0113 Total: 0.1430 \n",
            "Epoch [881], KL: 0.1327 L1Reg: 0.0106 Total: 0.1433 \n",
            "Epoch [882], KL: 0.1206 L1Reg: 0.0119 Total: 0.1325 \n",
            "Epoch [883], KL: 0.0943 L1Reg: 0.0115 Total: 0.1058 \n",
            "Epoch [884], KL: 0.1377 L1Reg: 0.0112 Total: 0.1489 \n",
            "Epoch [885], KL: 0.1250 L1Reg: 0.0110 Total: 0.1360 \n",
            "Epoch [886], KL: 0.1296 L1Reg: 0.0118 Total: 0.1413 \n",
            "Epoch [887], KL: 0.1344 L1Reg: 0.0115 Total: 0.1458 \n",
            "Epoch [888], KL: 0.1152 L1Reg: 0.0111 Total: 0.1262 \n",
            "Epoch [889], KL: 0.1145 L1Reg: 0.0108 Total: 0.1253 \n",
            "Epoch [890], KL: 0.1197 L1Reg: 0.0106 Total: 0.1303 \n",
            "Epoch [891], KL: 0.1269 L1Reg: 0.0120 Total: 0.1388 \n",
            "Epoch [892], KL: 0.1250 L1Reg: 0.0115 Total: 0.1365 \n",
            "Epoch [893], KL: 0.1347 L1Reg: 0.0129 Total: 0.1476 \n",
            "Epoch [894], KL: 0.1047 L1Reg: 0.0126 Total: 0.1173 \n",
            "Epoch [895], KL: 0.1068 L1Reg: 0.0120 Total: 0.1188 \n",
            "Epoch [896], KL: 0.1287 L1Reg: 0.0119 Total: 0.1406 \n",
            "Epoch [897], KL: 0.1180 L1Reg: 0.0118 Total: 0.1299 \n",
            "Epoch [898], KL: 0.1163 L1Reg: 0.0113 Total: 0.1276 \n",
            "Epoch [899], KL: 0.0985 L1Reg: 0.0110 Total: 0.1095 \n",
            "Epoch [900], KL: 0.1178 L1Reg: 0.0119 Total: 0.1297 \n",
            "Epoch [901], KL: 0.1101 L1Reg: 0.0126 Total: 0.1226 \n",
            "Epoch [902], KL: 0.1063 L1Reg: 0.0117 Total: 0.1180 \n",
            "Epoch [903], KL: 0.1302 L1Reg: 0.0114 Total: 0.1415 \n",
            "Epoch [904], KL: 0.1242 L1Reg: 0.0113 Total: 0.1355 \n",
            "Epoch [905], KL: 0.1113 L1Reg: 0.0110 Total: 0.1223 \n",
            "Epoch [906], KL: 0.1062 L1Reg: 0.0106 Total: 0.1169 \n",
            "Epoch [907], KL: 0.1182 L1Reg: 0.0109 Total: 0.1291 \n",
            "Epoch [908], KL: 0.1433 L1Reg: 0.0123 Total: 0.1557 \n",
            "Epoch [909], KL: 0.1194 L1Reg: 0.0117 Total: 0.1310 \n",
            "Epoch [910], KL: 0.1182 L1Reg: 0.0112 Total: 0.1294 \n",
            "Epoch [911], KL: 0.1318 L1Reg: 0.0111 Total: 0.1429 \n",
            "Epoch [912], KL: 0.1231 L1Reg: 0.0106 Total: 0.1337 \n",
            "Epoch [913], KL: 0.1136 L1Reg: 0.0123 Total: 0.1259 \n",
            "Epoch [914], KL: 0.1206 L1Reg: 0.0119 Total: 0.1324 \n",
            "Epoch [915], KL: 0.1339 L1Reg: 0.0115 Total: 0.1454 \n",
            "Epoch [916], KL: 0.1219 L1Reg: 0.0126 Total: 0.1345 \n",
            "Epoch [917], KL: 0.1258 L1Reg: 0.0122 Total: 0.1381 \n",
            "Epoch [918], KL: 0.1165 L1Reg: 0.0117 Total: 0.1282 \n",
            "Epoch [919], KL: 0.1250 L1Reg: 0.0113 Total: 0.1363 \n",
            "Epoch [920], KL: 0.1199 L1Reg: 0.0110 Total: 0.1309 \n",
            "Epoch [921], KL: 0.1131 L1Reg: 0.0107 Total: 0.1238 \n",
            "Epoch [922], KL: 0.1061 L1Reg: 0.0110 Total: 0.1172 \n",
            "Epoch [923], KL: 0.1098 L1Reg: 0.0110 Total: 0.1208 \n",
            "Epoch [924], KL: 0.1303 L1Reg: 0.0131 Total: 0.1434 \n",
            "Epoch [925], KL: 0.1140 L1Reg: 0.0129 Total: 0.1269 \n",
            "Epoch [926], KL: 0.1089 L1Reg: 0.0126 Total: 0.1216 \n",
            "Epoch [927], KL: 0.1025 L1Reg: 0.0123 Total: 0.1148 \n",
            "Epoch [928], KL: 0.0948 L1Reg: 0.0119 Total: 0.1068 \n",
            "Epoch [929], KL: 0.1077 L1Reg: 0.0115 Total: 0.1192 \n",
            "Epoch [930], KL: 0.0878 L1Reg: 0.0112 Total: 0.0990 \n",
            "Epoch [931], KL: 0.1223 L1Reg: 0.0121 Total: 0.1344 \n",
            "Epoch [932], KL: 0.1289 L1Reg: 0.0123 Total: 0.1412 \n",
            "Epoch [933], KL: 0.1256 L1Reg: 0.0116 Total: 0.1372 \n",
            "Epoch [934], KL: 0.1220 L1Reg: 0.0115 Total: 0.1335 \n",
            "Epoch [935], KL: 0.1299 L1Reg: 0.0109 Total: 0.1408 \n",
            "Epoch [936], KL: 0.1233 L1Reg: 0.0107 Total: 0.1340 \n",
            "Epoch [937], KL: 0.1376 L1Reg: 0.0124 Total: 0.1500 \n",
            "Epoch [938], KL: 0.1604 L1Reg: 0.0138 Total: 0.1742 \n",
            "Epoch [939], KL: 0.1207 L1Reg: 0.0129 Total: 0.1336 \n",
            "Epoch [940], KL: 0.1147 L1Reg: 0.0127 Total: 0.1273 \n",
            "Epoch [941], KL: 0.1328 L1Reg: 0.0121 Total: 0.1449 \n",
            "Epoch [942], KL: 0.1178 L1Reg: 0.0114 Total: 0.1292 \n",
            "Epoch [943], KL: 0.1281 L1Reg: 0.0114 Total: 0.1396 \n",
            "Epoch [944], KL: 0.1197 L1Reg: 0.0114 Total: 0.1310 \n",
            "Epoch [945], KL: 0.1259 L1Reg: 0.0119 Total: 0.1378 \n",
            "Epoch [946], KL: 0.1359 L1Reg: 0.0116 Total: 0.1475 \n",
            "Epoch [947], KL: 0.1353 L1Reg: 0.0114 Total: 0.1467 \n",
            "Epoch [948], KL: 0.0945 L1Reg: 0.0137 Total: 0.1082 \n",
            "Epoch [949], KL: 0.1156 L1Reg: 0.0137 Total: 0.1293 \n",
            "Epoch [950], KL: 0.1260 L1Reg: 0.0133 Total: 0.1393 \n",
            "Epoch [951], KL: 0.0871 L1Reg: 0.0124 Total: 0.0995 \n",
            "Epoch [952], KL: 0.1036 L1Reg: 0.0119 Total: 0.1155 \n",
            "Epoch [953], KL: 0.1212 L1Reg: 0.0116 Total: 0.1328 \n",
            "Epoch [954], KL: 0.0880 L1Reg: 0.0117 Total: 0.0997 \n",
            "Epoch [955], KL: 0.0971 L1Reg: 0.0118 Total: 0.1089 \n",
            "Epoch [956], KL: 0.1002 L1Reg: 0.0113 Total: 0.1115 \n",
            "Epoch [957], KL: 0.1181 L1Reg: 0.0112 Total: 0.1293 \n",
            "Epoch [958], KL: 0.1316 L1Reg: 0.0114 Total: 0.1430 \n",
            "Epoch [959], KL: 0.1369 L1Reg: 0.0118 Total: 0.1487 \n",
            "Epoch [960], KL: 0.1188 L1Reg: 0.0130 Total: 0.1318 \n",
            "Epoch [961], KL: 0.1219 L1Reg: 0.0135 Total: 0.1354 \n",
            "Epoch [962], KL: 0.1157 L1Reg: 0.0132 Total: 0.1289 \n",
            "Epoch [963], KL: 0.1279 L1Reg: 0.0126 Total: 0.1405 \n",
            "Epoch [964], KL: 0.1378 L1Reg: 0.0118 Total: 0.1497 \n",
            "Epoch [965], KL: 0.1325 L1Reg: 0.0115 Total: 0.1440 \n",
            "Epoch [966], KL: 0.1260 L1Reg: 0.0113 Total: 0.1373 \n",
            "Epoch [967], KL: 0.1139 L1Reg: 0.0111 Total: 0.1250 \n",
            "Epoch [968], KL: 0.1114 L1Reg: 0.0115 Total: 0.1229 \n",
            "Epoch [969], KL: 0.1163 L1Reg: 0.0112 Total: 0.1274 \n",
            "Epoch [970], KL: 0.1293 L1Reg: 0.0117 Total: 0.1410 \n",
            "Epoch [971], KL: 0.1471 L1Reg: 0.0138 Total: 0.1609 \n",
            "Epoch [972], KL: 0.1219 L1Reg: 0.0127 Total: 0.1346 \n",
            "Epoch [973], KL: 0.1117 L1Reg: 0.0123 Total: 0.1241 \n",
            "Epoch [974], KL: 0.1061 L1Reg: 0.0118 Total: 0.1179 \n",
            "Epoch [975], KL: 0.1020 L1Reg: 0.0115 Total: 0.1135 \n",
            "Epoch [976], KL: 0.1037 L1Reg: 0.0115 Total: 0.1151 \n",
            "Epoch [977], KL: 0.0982 L1Reg: 0.0113 Total: 0.1095 \n",
            "Epoch [978], KL: 0.0899 L1Reg: 0.0113 Total: 0.1012 \n",
            "Epoch [979], KL: 0.0966 L1Reg: 0.0113 Total: 0.1079 \n",
            "Epoch [980], KL: 0.1154 L1Reg: 0.0107 Total: 0.1262 \n",
            "Epoch [981], KL: 0.1205 L1Reg: 0.0119 Total: 0.1324 \n",
            "Epoch [982], KL: 0.1047 L1Reg: 0.0116 Total: 0.1163 \n",
            "Epoch [983], KL: 0.1238 L1Reg: 0.0126 Total: 0.1365 \n",
            "Epoch [984], KL: 0.1165 L1Reg: 0.0121 Total: 0.1286 \n",
            "Epoch [985], KL: 0.1106 L1Reg: 0.0118 Total: 0.1224 \n",
            "Epoch [986], KL: 0.1329 L1Reg: 0.0133 Total: 0.1461 \n",
            "Epoch [987], KL: 0.1448 L1Reg: 0.0123 Total: 0.1571 \n",
            "Epoch [988], KL: 0.1306 L1Reg: 0.0118 Total: 0.1424 \n",
            "Epoch [989], KL: 0.1452 L1Reg: 0.0114 Total: 0.1567 \n",
            "Epoch [990], KL: 0.1247 L1Reg: 0.0110 Total: 0.1357 \n",
            "Epoch [991], KL: 0.1098 L1Reg: 0.0109 Total: 0.1208 \n",
            "Epoch [992], KL: 0.1348 L1Reg: 0.0118 Total: 0.1466 \n",
            "Epoch [993], KL: 0.1417 L1Reg: 0.0135 Total: 0.1553 \n",
            "Epoch [994], KL: 0.1304 L1Reg: 0.0128 Total: 0.1432 \n",
            "Epoch [995], KL: 0.1361 L1Reg: 0.0123 Total: 0.1484 \n",
            "Epoch [996], KL: 0.1097 L1Reg: 0.0117 Total: 0.1214 \n",
            "Epoch [997], KL: 0.1111 L1Reg: 0.0115 Total: 0.1227 \n",
            "Epoch [998], KL: 0.1205 L1Reg: 0.0113 Total: 0.1319 \n",
            "Epoch [999], KL: 0.1250 L1Reg: 0.0115 Total: 0.1365 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stfr3rGtFaxU"
      },
      "source": [
        "### StyleGAN2-ADA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3HlM_S4Q0ws"
      },
      "source": [
        "from stylegan2.run_stylegan import *"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUn0DO6CNZg8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119fcd20-29ec-49ce-dd05-8faadf353f87"
      },
      "source": [
        "# Download our alexnet\n",
        "!python gdrivedl.py https://drive.google.com/open?id=1k8r765crSqarc4FV6aRTxbZZWpNaV3Gw checkpoints/"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoints/alexnet.pth\n",
            "[==================================================] 217.52MB/217.52MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1ymSH-oN1te"
      },
      "source": [
        "args = AttrDict()\n",
        "args.ckpt = None\n",
        "args.pretrainedRGNN = \"/content/Emotions-fromEEG-toArt/checkpoints/rgnn.pth\"\n",
        "args.pretrainedALEXNET = \"/content/Emotions-fromEEG-toArt/checkpoints/alexnet.pth\"\n",
        "args.patient = PATIENT\n",
        "args.output_folder = \"./output\"\n",
        "\n",
        "run_stylegan(args,eeg_dataloaders,wikiArt_dataloaders)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}