{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotions_fromEEG_toArt.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Jw6hnovB0SP9"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18hkM83wS0C4",
        "outputId": "0175b88f-488f-4fdc-e2b2-3b570e24daa4"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "user = 'manigalati'\n",
        "password = getpass(user)\n",
        "os.environ['GITHUB_AUTH'] = user + ':' + password\n",
        "!git clone https://$GITHUB_AUTH@github.com/PieraRiccio/Emotions-fromEEG-toArt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "manigalati··········\n",
            "Cloning into 'Emotions-fromEEG-toArt'...\n",
            "remote: Enumerating objects: 246, done.\u001b[K\n",
            "remote: Counting objects: 100% (246/246), done.\u001b[K\n",
            "remote: Compressing objects: 100% (231/231), done.\u001b[K\n",
            "remote: Total 246 (delta 71), reused 74 (delta 6), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (246/246), 33.98 MiB | 14.70 MiB/s, done.\n",
            "Resolving deltas: 100% (71/71), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srczRNOlTee5",
        "outputId": "12a4caa9-6fad-4d1f-d261-db050c128479"
      },
      "source": [
        "%cd Emotions-fromEEG-toArt/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Emotions-fromEEG-toArt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw6hnovB0SP9"
      },
      "source": [
        "## Install libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFsLzZvq0USx",
        "outputId": "9458aec2-391e-429f-9583-d8a76d1ed670"
      },
      "source": [
        "!pip install torch-scatter \\\n",
        "  torch-sparse \\\n",
        "  torch-cluster \\\n",
        "  torch-spline-conv \\\n",
        "  torch-geometric \\\n",
        "  -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Collecting torch-scatter\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_scatter-2.0.6-cp37-cp37m-linux_x86_64.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 6.3MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_sparse-0.6.9-cp37-cp37m-linux_x86_64.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 26.2MB/s \n",
            "\u001b[?25hCollecting torch-cluster\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 2.7MB/s \n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (386kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 5.5MB/s \n",
            "\u001b[?25hCollecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/99/18781f60303b2f7097a13feed0b51e531364251f441bd83e38fac09944bd/torch_geometric-1.7.0.tar.gz (212kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 11.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.5.1)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.51.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/36/de17e79f29e06d9a92746d0dd9ec4636487ab03f6af10e78586aae533f7a/ase-3.21.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 18.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric) (54.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric) (0.34.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.7.0-cp37-none-any.whl size=365386 sha256=9044e3687c1e646a0d650448ef426dec74eccbcea04a90b5a29239d95b4a4504\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/fb/df/37cd43d1433e65b2d3417a71438404d0eeb4fbbfa40730931c\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-cluster, torch-spline-conv, isodate, rdflib, ase, torch-geometric\n",
            "Successfully installed ase-3.21.1 isodate-0.6.0 rdflib-5.0.0 torch-cluster-1.5.9 torch-geometric-1.7.0 torch-scatter-2.0.6 torch-sparse-0.6.9 torch-spline-conv-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek68AcIKH9Z3"
      },
      "source": [
        "## WikiArt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-GiHjuYmnNR"
      },
      "source": [
        "from wikiArt.wikiArt_utils import *"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK0xQdLQlEVT"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB4N5YEgdCk7",
        "outputId": "ef54c9be-bfc7-465f-a880-906bf404fe65"
      },
      "source": [
        "!wget http://saifmohammad.com/WebDocs/WikiArt-Emotions.zip\n",
        "!unzip WikiArt-Emotions.zip\n",
        "!cp WikiArt-Emotions/WikiArt-Emotions-Ag4.tsv ./\n",
        "download_wikiArtEmotion(\"wikiArt/dataset\")\n",
        "!rm -r WikiArt-Emotions\n",
        "!rm -r __MACOSX/\n",
        "!rm WikiArt-Emotions-Ag4.tsv\n",
        "!rm WikiArt-Emotions.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-17 15:19:23--  http://saifmohammad.com/WebDocs/WikiArt-Emotions.zip\n",
            "Resolving saifmohammad.com (saifmohammad.com)... 192.185.17.122\n",
            "Connecting to saifmohammad.com (saifmohammad.com)|192.185.17.122|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2474686 (2.4M) [application/zip]\n",
            "Saving to: ‘WikiArt-Emotions.zip’\n",
            "\n",
            "WikiArt-Emotions.zi 100%[===================>]   2.36M  2.57MB/s    in 0.9s    \n",
            "\n",
            "2021-04-17 15:19:24 (2.57 MB/s) - ‘WikiArt-Emotions.zip’ saved [2474686/2474686]\n",
            "\n",
            "Archive:  WikiArt-Emotions.zip\n",
            "   creating: WikiArt-Emotions/\n",
            "  inflating: WikiArt-Emotions/WikiArt-Emotions-All.tsv  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/WikiArt-Emotions/\n",
            "  inflating: __MACOSX/WikiArt-Emotions/._WikiArt-Emotions-All.tsv  \n",
            "  inflating: WikiArt-Emotions/WikiArt-annotations.csv  \n",
            "  inflating: __MACOSX/WikiArt-Emotions/._WikiArt-annotations.csv  \n",
            "  inflating: WikiArt-Emotions/WikiArt-info.tsv  \n",
            "  inflating: __MACOSX/WikiArt-Emotions/._WikiArt-info.tsv  \n",
            "  inflating: WikiArt-Emotions/README.txt  \n",
            "  inflating: __MACOSX/WikiArt-Emotions/._README.txt  \n",
            "  inflating: WikiArt-Emotions/WikiArt-Emotions-Ag5.tsv  \n",
            "  inflating: __MACOSX/WikiArt-Emotions/._WikiArt-Emotions-Ag5.tsv  \n",
            "  inflating: WikiArt-Emotions/WikiArt-Emotions-Ag4.tsv  \n",
            "  inflating: __MACOSX/WikiArt-Emotions/._WikiArt-Emotions-Ag4.tsv  \n",
            "  inflating: WikiArt-Emotions/WikiArt-Emotions-Ag3.tsv  \n",
            "  inflating: __MACOSX/WikiArt-Emotions/._WikiArt-Emotions-Ag3.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QETmCcrK2wK"
      },
      "source": [
        "### Outliers removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3BgYL__HIPJ"
      },
      "source": [
        "import pickle\n",
        "with open('wikiArt/selection.pkl','rb') as f:\n",
        "  selection=pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Lk8genHiHV"
      },
      "source": [
        "for image in os.listdir(\"wikiArt/dataset/happiness_optimism\"):\n",
        "  if image not in selection:\n",
        "    !rm \"wikiArt/dataset/happiness_optimism/{image}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU44pbMERRgG"
      },
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C-sV43iRPx4"
      },
      "source": [
        "for group in os.listdir(\"wikiArt/dataset\"):\n",
        "  print(\"{}: {}\".format(group,len(os.listdir(os.path.join(\"wikiArt/dataset\",group)))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5mTYyA3tdp-"
      },
      "source": [
        "data_augmentation(\"wikiArt/dataset\",[\"anger_disgust\",\"fear_shame\",\"sadness_pessimism\"],len(os.listdir(\"wikiArt/dataset/happiness_optimism\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsrbJVDEdJja"
      },
      "source": [
        "for group in os.listdir(\"wikiArt/dataset\"):\n",
        "  print(\"{}: {}\".format(group,len(os.listdir(os.path.join(\"wikiArt/dataset\",group)))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMK8BKwllMXn"
      },
      "source": [
        "### Pre-process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpcXjaGdn9bB"
      },
      "source": [
        "wikiArt_dict=preprocess_wikiart(\"wikiArt/dataset\")\n",
        "np.save(\"wikiArt_dict\",wikiArt_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD_MYpHjli6t"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXuT0PBftpLg"
      },
      "source": [
        "wikiArt_dict=np.load(\"wikiArt_dict.npy\",allow_pickle=True).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B1QEDn7trj6"
      },
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True)\n",
        "])\n",
        "\n",
        "BATCH_SIZE=8\n",
        "wikiArt_dataloaders = {\n",
        "    \"anger_disgust\": torch.utils.data.DataLoader(WikiArtDataLoader(wikiArt_dict[\"anger_disgust\"],transform=transform),batch_size=BATCH_SIZE,shuffle=False,num_workers=0,drop_last=True),\n",
        "    \"sadness_pessimism\": torch.utils.data.DataLoader(WikiArtDataLoader(wikiArt_dict[\"sadness_pessimism\"],transform=transform),batch_size=BATCH_SIZE,shuffle=False,num_workers=0,drop_last=True),\n",
        "    \"fear_shame\": torch.utils.data.DataLoader(WikiArtDataLoader(wikiArt_dict[\"fear_shame\"],transform=transform),batch_size=BATCH_SIZE,shuffle=False,num_workers=0,drop_last=True),\n",
        "    \"happiness_optimism\": torch.utils.data.DataLoader(WikiArtDataLoader(wikiArt_dict[\"happiness_optimism\"],transform=transform),batch_size=BATCH_SIZE,shuffle=False,num_workers=0,drop_last=True)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEmwaQFPSg9w"
      },
      "source": [
        "## SEED-IV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJT6GSbNpSr1"
      },
      "source": [
        "from seed_iv.seedIV_utils import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZRLrpR3pd-W"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59SkDF1ShekD"
      },
      "source": [
        "We assume at this point that the user has already got the access to the SEED-IV dataset, and imported a .zip file with the following structure:\n",
        "\n",
        "- **seed-iv.zip**\n",
        " - 1.zip\n",
        " - 2.zip\n",
        " - 3.zip\n",
        " - Channel Order.xlsx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd3nNVqTWKWs",
        "outputId": "77bb61a0-aa0b-41dd-86a8-b5b851b7cbdf"
      },
      "source": [
        "!unzip seed-iv.zip -d seed_iv && rm seed-iv.zip\n",
        "!unzip seed_iv/1.zip -d seed_iv/dataset && rm seed_iv/1.zip\n",
        "!unzip seed_iv/2.zip -d seed_iv/dataset && rm seed_iv/2.zip\n",
        "!unzip seed_iv/3.zip -d seed_iv/dataset && rm seed_iv/3.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  seed_iv/1.zip\n",
            "  inflating: seed_iv/dataset/1/1_20160518.mat  \n",
            "  inflating: seed_iv/dataset/1/10_20151014.mat  \n",
            "  inflating: seed_iv/dataset/1/11_20150916.mat  \n",
            "  inflating: seed_iv/dataset/1/12_20150725.mat  \n",
            "  inflating: seed_iv/dataset/1/13_20151115.mat  \n",
            "  inflating: seed_iv/dataset/1/14_20151205.mat  \n",
            "  inflating: seed_iv/dataset/1/15_20150508.mat  \n",
            "  inflating: seed_iv/dataset/1/2_20150915.mat  \n",
            "  inflating: seed_iv/dataset/1/3_20150919.mat  \n",
            "  inflating: seed_iv/dataset/1/4_20151111.mat  \n",
            "  inflating: seed_iv/dataset/1/5_20160406.mat  \n",
            "  inflating: seed_iv/dataset/1/6_20150507.mat  \n",
            "  inflating: seed_iv/dataset/1/7_20150715.mat  \n",
            "  inflating: seed_iv/dataset/1/8_20151103.mat  \n",
            "  inflating: seed_iv/dataset/1/9_20151028.mat  \n",
            "Archive:  seed_iv/2.zip\n",
            "  inflating: seed_iv/dataset/2/1_20161125.mat  \n",
            "  inflating: seed_iv/dataset/2/10_20151021.mat  \n",
            "  inflating: seed_iv/dataset/2/11_20150921.mat  \n",
            "  inflating: seed_iv/dataset/2/12_20150804.mat  \n",
            "  inflating: seed_iv/dataset/2/13_20151125.mat  \n",
            "  inflating: seed_iv/dataset/2/14_20151208.mat  \n",
            "  inflating: seed_iv/dataset/2/15_20150514.mat  \n",
            "  inflating: seed_iv/dataset/2/2_20150920.mat  \n",
            "  inflating: seed_iv/dataset/2/3_20151018.mat  \n",
            "  inflating: seed_iv/dataset/2/4_20151118.mat  \n",
            "  inflating: seed_iv/dataset/2/5_20160413.mat  \n",
            "  inflating: seed_iv/dataset/2/6_20150511.mat  \n",
            "  inflating: seed_iv/dataset/2/7_20150717.mat  \n",
            "  inflating: seed_iv/dataset/2/8_20151110.mat  \n",
            "  inflating: seed_iv/dataset/2/9_20151119.mat  \n",
            "Archive:  seed_iv/3.zip\n",
            "  inflating: seed_iv/dataset/3/1_20161126.mat  \n",
            "  inflating: seed_iv/dataset/3/10_20151023.mat  \n",
            "  inflating: seed_iv/dataset/3/11_20151011.mat  \n",
            "  inflating: seed_iv/dataset/3/12_20150807.mat  \n",
            "  inflating: seed_iv/dataset/3/13_20161130.mat  \n",
            "  inflating: seed_iv/dataset/3/14_20151215.mat  \n",
            "  inflating: seed_iv/dataset/3/15_20150527.mat  \n",
            "  inflating: seed_iv/dataset/3/2_20151012.mat  \n",
            "  inflating: seed_iv/dataset/3/3_20151101.mat  \n",
            "  inflating: seed_iv/dataset/3/4_20151123.mat  \n",
            "  inflating: seed_iv/dataset/3/5_20160420.mat  \n",
            "  inflating: seed_iv/dataset/3/6_20150512.mat  \n",
            "  inflating: seed_iv/dataset/3/7_20150721.mat  \n",
            "  inflating: seed_iv/dataset/3/8_20151117.mat  \n",
            "  inflating: seed_iv/dataset/3/9_20151209.mat  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCMAvvU0pgK0"
      },
      "source": [
        "### Pre-process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqZJgAM7xuft"
      },
      "source": [
        "labels = emotionDL(eps=0.1)\n",
        "eeg_dict=load_data(\"seed_iv/dataset\",labels)\n",
        "np.save(\"eeg_dict\",eeg_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iN-T0LSBdmP",
        "outputId": "fd56527e-a39a-4a18-b113-f59a67b4dfe5"
      },
      "source": [
        "for p in eeg_dict.keys():\n",
        "  print(\"\\nPATIENT {}\".format(p))\n",
        "  print(\"neutral:\\ttrain: {:d}\\tval: {:d}\".format(len(eeg_dict[p][\"neutral\"][\"train\"]),len(eeg_dict[p][\"neutral\"][\"val\"])))\n",
        "  print(\"sadness:\\ttrain: {:d}\\tval: {:d}\".format(len(eeg_dict[p][\"sadness\"][\"train\"]),len(eeg_dict[p][\"sadness\"][\"val\"])))\n",
        "  print(\"fear:\\t\\ttrain: {:d}\\tval: {:d}\".format(len(eeg_dict[p][\"fear\"][\"train\"]),len(eeg_dict[p][\"fear\"][\"val\"])))\n",
        "  print(\"happiness:\\ttrain: {:d}\\tval: {:d}\".format(len(eeg_dict[p][\"happiness\"][\"train\"]),len(eeg_dict[p][\"happiness\"][\"val\"])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "PATIENT 11\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 8\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 10\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 3\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 12\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 6\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 13\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 2\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 7\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 4\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 1\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 9\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 5\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 15\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 14\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZcPRJkfCJu-"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOgpQ_7ZOWh2"
      },
      "source": [
        "eeg_dict=np.load(\"eeg_dict.npy\",allow_pickle=True).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZkzgRmlOWh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f7b618-af0c-462f-bffc-660dd482ffab"
      },
      "source": [
        "adjacency_matrix=get_adjacency_matrix(\"seed_iv/Channel Order.xlsx\",\"seed_iv/Channel Location.txt\")\n",
        "adjacency_matrix=torch.tensor(adjacency_matrix, dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Emotions-fromEEG-toArt/seed_iv/seedIV_utils.py:103: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  adjacency_matrix = np.minimum(np.ones([62,62]), delta/(distances_matrix**2))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvxa--JtOWh3"
      },
      "source": [
        "BATCH_SIZE=8\n",
        "eeg_dataloaders = {}\n",
        "for p in eeg_dict.keys():\n",
        "  eeg_dataloaders[p]={\n",
        "    \"neutral\": {\n",
        "      \"train\": torch_geometric.data.DataLoader(eeg_dict[p][\"neutral\"][\"train\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True),\n",
        "      \"val\": torch_geometric.data.DataLoader(eeg_dict[p][\"neutral\"][\"val\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "    },\n",
        "    \"sadness\": {\n",
        "      \"train\": torch_geometric.data.DataLoader(eeg_dict[p][\"sadness\"][\"train\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True),\n",
        "      \"val\": torch_geometric.data.DataLoader(eeg_dict[p][\"sadness\"][\"val\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "    },\n",
        "    \"fear\": {\n",
        "      \"train\": torch_geometric.data.DataLoader(eeg_dict[p][\"fear\"][\"train\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True),\n",
        "      \"val\": torch_geometric.data.DataLoader(eeg_dict[p][\"fear\"][\"val\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "    },\n",
        "    \"happiness\": {\n",
        "      \"train\": torch_geometric.data.DataLoader(eeg_dict[p][\"happiness\"][\"train\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True),\n",
        "      \"val\": torch_geometric.data.DataLoader(eeg_dict[p][\"happiness\"][\"val\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "    }\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdWfBdGyaQfA"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIyz1iJzj5W7"
      },
      "source": [
        "PATIENT=15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gH8161TAaUMj"
      },
      "source": [
        "### RGNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhsZLf_Nuwez"
      },
      "source": [
        "from rgnn.RGNN_utils import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "mmgHr_kClLqo",
        "outputId": "4d12add3-0548-4ea2-9c78-066ff6089c3c"
      },
      "source": [
        "N_EPOCHS=1000\n",
        "\n",
        "classifier = SymSimGCNNet(62, True,torch.tensor(adjacency_matrix, dtype=torch.float32), 5, (50, 50), 4, 2, dropout=0.7)\n",
        "classifier = classifier.to(device)\n",
        "history, best_model_dict = training_routine(classifier, N_EPOCHS,\n",
        "  EEG_Sampler([\n",
        "    v[\"train\"] for v in eeg_dataloaders[PATIENT].values()\n",
        "  ]),\n",
        "  EEG_Sampler([\n",
        "    v[\"val\"] for v in eeg_dataloaders[PATIENT].values()\n",
        "  ]),\n",
        "  \"./checkpoints\"\n",
        ")\n",
        "plot_history(history)\n",
        "classifier.load_state_dict(best_model_dict);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/content/Emotions-fromEEG-toArt/rgnn/RGNN_utils.py:167: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = F.log_softmax(x)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2611: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
            "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], KL: 15.5019 L1Reg: 0.1997 Total: 15.7016 \n",
            "Epoch [1], KL: 0.8177 L1Reg: 0.2031 Total: 1.0207 \n",
            "Epoch [2], KL: 0.4696 L1Reg: 0.2086 Total: 0.6782 \n",
            "Epoch [3], KL: 0.3382 L1Reg: 0.2104 Total: 0.5486 \n",
            "Epoch [4], KL: 0.3249 L1Reg: 0.2112 Total: 0.5362 \n",
            "Epoch [5], KL: 0.3161 L1Reg: 0.2116 Total: 0.5277 \n",
            "Epoch [6], KL: 0.3098 L1Reg: 0.2117 Total: 0.5214 \n",
            "Epoch [7], KL: 0.2966 L1Reg: 0.2114 Total: 0.5079 \n",
            "Epoch [8], KL: 0.2670 L1Reg: 0.2109 Total: 0.4779 \n",
            "Epoch [9], KL: 0.2540 L1Reg: 0.2104 Total: 0.4644 \n",
            "Epoch [10], KL: 0.2570 L1Reg: 0.2098 Total: 0.4668 \n",
            "Epoch [11], KL: 0.2559 L1Reg: 0.2091 Total: 0.4649 \n",
            "Epoch [12], KL: 0.2508 L1Reg: 0.2085 Total: 0.4593 \n",
            "Epoch [13], KL: 0.2820 L1Reg: 0.2077 Total: 0.4898 \n",
            "Epoch [14], KL: 0.2837 L1Reg: 0.2070 Total: 0.4907 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7fb37e4be416>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meeg_dataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPATIENT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   ]),\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0;34m\"./checkpoints\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[0mplot_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Emotions-fromEEG-toArt/rgnn/RGNN_utils.py\u001b[0m in \u001b[0;36mtraining_routine\u001b[0;34m(model, epochs, train_loader, val_loader, ckpt_folder)\u001b[0m\n\u001b[1;32m    207\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stfr3rGtFaxU"
      },
      "source": [
        "### StyleGAN2-ADA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3HlM_S4Q0ws"
      },
      "source": [
        "from stylegan2.run_stylegan import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUn0DO6CNZg8"
      },
      "source": [
        "# Download our alexnet\n",
        "!python gdrivedl.py https://drive.google.com/open?id=1k8r765crSqarc4FV6aRTxbZZWpNaV3Gw checkpoints/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "-1ymSH-oN1te",
        "outputId": "630128ff-36f7-4cba-82c3-51e3020d9caa"
      },
      "source": [
        "args = AttrDict()\n",
        "args.ckpt = None\n",
        "args.pretrainedRGNN = \"/content/Emotions-fromEEG-toArt/checkpoints/rgnn.pth\"\n",
        "args.pretrainedALEXNET = \"/content/Emotions-fromEEG-toArt/checkpoints/alexnet.pth\"\n",
        "args.patient = PATIENT\n",
        "args.output_folder = \"./output\"\n",
        "\n",
        "run_stylegan(args,eeg_dataloaders,wikiArt_dataloaders)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/800000 [00:00<?, ?it/s]/content/Emotions-fromEEG-toArt/rgnn/RGNN_utils.py:167: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = F.log_softmax(x)\n",
            "d: 0.9475; g: 13.2533; r1: 0.0018; path: 2.1683; mean path: 0.0147; augment: 0.0000;:   0%|          | 0/800000 [00:02<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n",
            "d: 0.4985; g: 2.9457; r1: 0.0120; path: 0.0027; mean path: 0.1438; augment: 0.0031;:   0%|          | 226/800000 [02:35<338:40:47,  1.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-fe4f3d604560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./output\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrun_stylegan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meeg_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwikiArt_dataloaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/Emotions-fromEEG-toArt/stylegan2/run_stylegan.py\u001b[0m in \u001b[0;36mrun_stylegan\u001b[0;34m(args, eeg_dataloaders, wikiArt_dataloaders)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m       \u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmixing_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmixing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m       \u001b[0mfake_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meeg_latent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Emotions-fromEEG-toArt/stylegan2/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, styles, labels, return_latents, inject_index, truncation, truncation_latent, input_is_latent, noise, randomize_noise)\u001b[0m\n\u001b[1;32m    535\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_rgb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Emotions-fromEEG-toArt/stylegan2/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, style, skip)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mskip\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m             \u001b[0mskip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Emotions-fromEEG-toArt/stylegan2/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupfirdn2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Emotions-fromEEG-toArt/stylegan2/op/upfirdn2d.py\u001b[0m in \u001b[0;36mupfirdn2d\u001b[0;34m(input, kernel, up, down, pad)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         out = UpFirDn2d.apply(\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdown\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         )\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Emotions-fromEEG-toArt/stylegan2/op/upfirdn2d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, kernel, up, down, pad)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mout_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0min_h\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mup_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpad_y0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpad_y1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mkernel_h\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mdown_y\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}