{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotions_fromEEG_toArt.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Jw6hnovB0SP9"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18hkM83wS0C4",
        "outputId": "e05e4d00-6457-4d58-91e6-dfac6b83dd45"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "user = 'manigalati'\n",
        "password = getpass(user)\n",
        "os.environ['GITHUB_AUTH'] = user + ':' + password\n",
        "!git clone https://$GITHUB_AUTH@github.com/PieraRiccio/Emotions-fromEEG-toArt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "manigalati··········\n",
            "Cloning into 'Emotions-fromEEG-toArt'...\n",
            "remote: Enumerating objects: 199, done.\u001b[K\n",
            "remote: Counting objects: 100% (199/199), done.\u001b[K\n",
            "remote: Compressing objects: 100% (187/187), done.\u001b[K\n",
            "remote: Total 199 (delta 54), reused 75 (delta 6), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (199/199), 33.94 MiB | 33.29 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srczRNOlTee5",
        "outputId": "247b5da8-f7c6-4c70-e92e-5ff58d311645"
      },
      "source": [
        "%cd Emotions-fromEEG-toArt/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Emotions-fromEEG-toArt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jw6hnovB0SP9"
      },
      "source": [
        "## Install libs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFsLzZvq0USx",
        "outputId": "9ecf9ba8-7ec3-4a3d-c879-8a08de42d6e8"
      },
      "source": [
        "!pip install torch-scatter \\\n",
        "  torch-sparse \\\n",
        "  torch-cluster \\\n",
        "  torch-spline-conv \\\n",
        "  torch-geometric \\\n",
        "  -f https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-1.8.0+cu101.html\n",
            "Collecting torch-scatter\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_scatter-2.0.6-cp37-cp37m-linux_x86_64.whl (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 32.6MB/s \n",
            "\u001b[?25hCollecting torch-sparse\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_sparse-0.6.9-cp37-cp37m-linux_x86_64.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 31.7MB/s \n",
            "\u001b[?25hCollecting torch-cluster\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_cluster-1.5.9-cp37-cp37m-linux_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 31.8MB/s \n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "\u001b[?25l  Downloading https://pytorch-geometric.com/whl/torch-1.8.0%2Bcu101/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl (386kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 36.3MB/s \n",
            "\u001b[?25hCollecting torch-geometric\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/99/18781f60303b2f7097a13feed0b51e531364251f441bd83e38fac09944bd/torch_geometric-1.7.0.tar.gz (212kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 17.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.41.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.5)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.15)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.22.2.post1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.51.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.1.5)\n",
            "Collecting rdflib\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/6b/6454aa1db753c0f8bc265a5bd5c10b5721a4bb24160fb4faf758cf6be8a1/rdflib-5.0.0-py3-none-any.whl (231kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 37.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.10.0)\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (0.4)\n",
            "Collecting ase\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/36/de17e79f29e06d9a92746d0dd9ec4636487ab03f6af10e78586aae533f7a/ase-3.21.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 29.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx->torch-geometric) (4.4.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric) (54.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->torch-geometric) (0.34.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torch-geometric) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (1.15.0)\n",
            "Collecting isodate\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from rdflib->torch-geometric) (2.4.7)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ase->torch-geometric) (3.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (1.1.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->ase->torch-geometric) (0.10.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-1.7.0-cp37-none-any.whl size=365386 sha256=e98346fdde8e09db5e29e92e410a4c6cb056ca41101ba64c8f34fe4dbd38a8c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/fb/df/37cd43d1433e65b2d3417a71438404d0eeb4fbbfa40730931c\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-scatter, torch-sparse, torch-cluster, torch-spline-conv, isodate, rdflib, ase, torch-geometric\n",
            "Successfully installed ase-3.21.1 isodate-0.6.0 rdflib-5.0.0 torch-cluster-1.5.9 torch-geometric-1.7.0 torch-scatter-2.0.6 torch-sparse-0.6.9 torch-spline-conv-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek68AcIKH9Z3"
      },
      "source": [
        "## WikiArt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-GiHjuYmnNR"
      },
      "source": [
        "from wikiArt.wikiArt_utils import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK0xQdLQlEVT"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB4N5YEgdCk7",
        "outputId": "a6382d28-b11a-4aaa-a676-14ab4889792c"
      },
      "source": [
        "!wget http://saifmohammad.com/WebDocs/WikiArt-Emotions.zip\n",
        "!unzip WikiArt-Emotions.zip\n",
        "!cp WikiArt-Emotions/WikiArt-Emotions-Ag4.tsv ./\n",
        "download_wikiArtEmotion(\"wikiArt/dataset\")\n",
        "!rm -r WikiArt-Emotions\n",
        "!rm -r __MACOSX/\n",
        "!rm WikiArt-Emotions-Ag4.tsv\n",
        "!rm WikiArt-Emotions.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-11 11:36:47--  http://saifmohammad.com/WebDocs/WikiArt-Emotions.zip\n",
            "Resolving saifmohammad.com (saifmohammad.com)... 192.185.17.122\n",
            "Connecting to saifmohammad.com (saifmohammad.com)|192.185.17.122|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2474686 (2.4M) [application/zip]\n",
            "Saving to: ‘WikiArt-Emotions.zip’\n",
            "\n",
            "WikiArt-Emotions.zi 100%[===================>]   2.36M  3.35MB/s    in 0.7s    \n",
            "\n",
            "2021-04-11 11:36:48 (3.35 MB/s) - ‘WikiArt-Emotions.zip’ saved [2474686/2474686]\n",
            "\n",
            "Archive:  WikiArt-Emotions.zip\n",
            "   creating: WikiArt-Emotions/\n",
            "  inflating: WikiArt-Emotions/WikiArt-Emotions-All.tsv  \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/WikiArt-Emotions/\n",
            "  inflating: __MACOSX/WikiArt-Emotions/._WikiArt-Emotions-All.tsv  \n",
            "  inflating: WikiArt-Emotions/WikiArt-annotations.csv  \n",
            "  inflating: __MACOSX/WikiArt-Emotions/._WikiArt-annotations.csv  \n",
            "  inflating: WikiArt-Emotions/WikiArt-info.tsv  \n",
            "  inflating: __MACOSX/WikiArt-Emotions/._WikiArt-info.tsv  \n",
            "  inflating: WikiArt-Emotions/README.txt  \n",
            "  inflating: __MACOSX/WikiArt-Emotions/._README.txt  \n",
            "  inflating: WikiArt-Emotions/WikiArt-Emotions-Ag5.tsv  \n",
            "  inflating: __MACOSX/WikiArt-Emotions/._WikiArt-Emotions-Ag5.tsv  \n",
            "  inflating: WikiArt-Emotions/WikiArt-Emotions-Ag4.tsv  \n",
            "  inflating: __MACOSX/WikiArt-Emotions/._WikiArt-Emotions-Ag4.tsv  \n",
            "  inflating: WikiArt-Emotions/WikiArt-Emotions-Ag3.tsv  \n",
            "  inflating: __MACOSX/WikiArt-Emotions/._WikiArt-Emotions-Ag3.tsv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QETmCcrK2wK"
      },
      "source": [
        "### Outliers removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3BgYL__HIPJ"
      },
      "source": [
        "import pickle\n",
        "with open('wikiArt/selection.pkl','rb') as f:\n",
        "  selection=pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8Lk8genHiHV"
      },
      "source": [
        "for image in os.listdir(\"wikiArt/dataset/happiness_optimism\"):\n",
        "  if image not in selection:\n",
        "    !rm \"wikiArt/dataset/happiness_optimism/{image}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU44pbMERRgG"
      },
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C-sV43iRPx4",
        "outputId": "d9738468-0835-4d08-8720-6fc4c600207b"
      },
      "source": [
        "for group in os.listdir(\"wikiArt/dataset\"):\n",
        "  print(\"{}: {}\".format(group,len(os.listdir(os.path.join(\"wikiArt/dataset\",group)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fear_shame: 214\n",
            "anger_disgust: 67\n",
            "happiness_optimism: 688\n",
            "sadness_pessimism: 258\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5mTYyA3tdp-"
      },
      "source": [
        "data_augmentation(\"wikiArt/dataset\",[\"anger_disgust\",\"fear_shame\",\"sadness_pessimism\"],len(os.listdir(\"wikiArt/dataset/happiness_optimism\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IsrbJVDEdJja",
        "outputId": "5754de1c-1239-471b-98b0-5b46c0039b9f"
      },
      "source": [
        "for group in os.listdir(\"wikiArt/dataset\"):\n",
        "  print(\"{}: {}\".format(group,len(os.listdir(os.path.join(\"wikiArt/dataset\",group)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fear_shame: 690\n",
            "anger_disgust: 487\n",
            "happiness_optimism: 688\n",
            "sadness_pessimism: 690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMK8BKwllMXn"
      },
      "source": [
        "### Pre-process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpcXjaGdn9bB"
      },
      "source": [
        "wikiArt_dict=preprocess_wikiart(\"wikiArt/dataset\")\n",
        "np.save(\"wikiArt_dict\",wikiArt_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WD_MYpHjli6t"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXuT0PBftpLg"
      },
      "source": [
        "wikiArt_dict=np.load(\"wikiArt_dict.npy\",allow_pickle=True).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B1QEDn7trj6"
      },
      "source": [
        "transform = torchvision.transforms.Compose([\n",
        "    torchvision.transforms.RandomHorizontalFlip(),\n",
        "    torchvision.transforms.ToTensor(),\n",
        "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True)\n",
        "])\n",
        "\n",
        "BATCH_SIZE=8\n",
        "wikiArt_dataloaders = {\n",
        "    \"anger_disgust\": torch.utils.data.DataLoader(WikiArtDataLoader(wikiArt_dict[\"anger_disgust\"],transform=transform),batch_size=BATCH_SIZE,shuffle=False,num_workers=0,drop_last=True),\n",
        "    \"sadness_pessimism\": torch.utils.data.DataLoader(WikiArtDataLoader(wikiArt_dict[\"sadness_pessimism\"],transform=transform),batch_size=BATCH_SIZE,shuffle=False,num_workers=0,drop_last=True),\n",
        "    \"fear_shame\": torch.utils.data.DataLoader(WikiArtDataLoader(wikiArt_dict[\"fear_shame\"],transform=transform),batch_size=BATCH_SIZE,shuffle=False,num_workers=0,drop_last=True),\n",
        "    \"happiness_optimism\": torch.utils.data.DataLoader(WikiArtDataLoader(wikiArt_dict[\"happiness_optimism\"],transform=transform),batch_size=BATCH_SIZE,shuffle=False,num_workers=0,drop_last=True)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEmwaQFPSg9w"
      },
      "source": [
        "## SEED-IV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJT6GSbNpSr1"
      },
      "source": [
        "from seed_iv.seedIV_utils import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZRLrpR3pd-W"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59SkDF1ShekD"
      },
      "source": [
        "We assume at this point that the user has already got the access to the SEED-IV dataset, and imported a .zip file with the following structure:\n",
        "\n",
        "- **seed-iv.zip**\n",
        " - 1.zip\n",
        " - 2.zip\n",
        " - 3.zip\n",
        " - Channel Order.xlsx"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fd3nNVqTWKWs",
        "outputId": "77bb61a0-aa0b-41dd-86a8-b5b851b7cbdf"
      },
      "source": [
        "!unzip seed-iv.zip -d seed_iv && rm seed-iv.zip\n",
        "!unzip seed_iv/1.zip -d seed_iv/dataset && rm seed_iv/1.zip\n",
        "!unzip seed_iv/2.zip -d seed_iv/dataset && rm seed_iv/2.zip\n",
        "!unzip seed_iv/3.zip -d seed_iv/dataset && rm seed_iv/3.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  seed_iv/1.zip\n",
            "  inflating: seed_iv/dataset/1/1_20160518.mat  \n",
            "  inflating: seed_iv/dataset/1/10_20151014.mat  \n",
            "  inflating: seed_iv/dataset/1/11_20150916.mat  \n",
            "  inflating: seed_iv/dataset/1/12_20150725.mat  \n",
            "  inflating: seed_iv/dataset/1/13_20151115.mat  \n",
            "  inflating: seed_iv/dataset/1/14_20151205.mat  \n",
            "  inflating: seed_iv/dataset/1/15_20150508.mat  \n",
            "  inflating: seed_iv/dataset/1/2_20150915.mat  \n",
            "  inflating: seed_iv/dataset/1/3_20150919.mat  \n",
            "  inflating: seed_iv/dataset/1/4_20151111.mat  \n",
            "  inflating: seed_iv/dataset/1/5_20160406.mat  \n",
            "  inflating: seed_iv/dataset/1/6_20150507.mat  \n",
            "  inflating: seed_iv/dataset/1/7_20150715.mat  \n",
            "  inflating: seed_iv/dataset/1/8_20151103.mat  \n",
            "  inflating: seed_iv/dataset/1/9_20151028.mat  \n",
            "Archive:  seed_iv/2.zip\n",
            "  inflating: seed_iv/dataset/2/1_20161125.mat  \n",
            "  inflating: seed_iv/dataset/2/10_20151021.mat  \n",
            "  inflating: seed_iv/dataset/2/11_20150921.mat  \n",
            "  inflating: seed_iv/dataset/2/12_20150804.mat  \n",
            "  inflating: seed_iv/dataset/2/13_20151125.mat  \n",
            "  inflating: seed_iv/dataset/2/14_20151208.mat  \n",
            "  inflating: seed_iv/dataset/2/15_20150514.mat  \n",
            "  inflating: seed_iv/dataset/2/2_20150920.mat  \n",
            "  inflating: seed_iv/dataset/2/3_20151018.mat  \n",
            "  inflating: seed_iv/dataset/2/4_20151118.mat  \n",
            "  inflating: seed_iv/dataset/2/5_20160413.mat  \n",
            "  inflating: seed_iv/dataset/2/6_20150511.mat  \n",
            "  inflating: seed_iv/dataset/2/7_20150717.mat  \n",
            "  inflating: seed_iv/dataset/2/8_20151110.mat  \n",
            "  inflating: seed_iv/dataset/2/9_20151119.mat  \n",
            "Archive:  seed_iv/3.zip\n",
            "  inflating: seed_iv/dataset/3/1_20161126.mat  \n",
            "  inflating: seed_iv/dataset/3/10_20151023.mat  \n",
            "  inflating: seed_iv/dataset/3/11_20151011.mat  \n",
            "  inflating: seed_iv/dataset/3/12_20150807.mat  \n",
            "  inflating: seed_iv/dataset/3/13_20161130.mat  \n",
            "  inflating: seed_iv/dataset/3/14_20151215.mat  \n",
            "  inflating: seed_iv/dataset/3/15_20150527.mat  \n",
            "  inflating: seed_iv/dataset/3/2_20151012.mat  \n",
            "  inflating: seed_iv/dataset/3/3_20151101.mat  \n",
            "  inflating: seed_iv/dataset/3/4_20151123.mat  \n",
            "  inflating: seed_iv/dataset/3/5_20160420.mat  \n",
            "  inflating: seed_iv/dataset/3/6_20150512.mat  \n",
            "  inflating: seed_iv/dataset/3/7_20150721.mat  \n",
            "  inflating: seed_iv/dataset/3/8_20151117.mat  \n",
            "  inflating: seed_iv/dataset/3/9_20151209.mat  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCMAvvU0pgK0"
      },
      "source": [
        "### Pre-process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqZJgAM7xuft"
      },
      "source": [
        "labels = emotionDL(eps=0.1)\n",
        "eeg_dict=load_data(\"seed_iv/dataset\",labels)\n",
        "np.save(\"eeg_dict\",eeg_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iN-T0LSBdmP",
        "outputId": "fd56527e-a39a-4a18-b113-f59a67b4dfe5"
      },
      "source": [
        "for p in eeg_dict.keys():\n",
        "  print(\"\\nPATIENT {}\".format(p))\n",
        "  print(\"neutral:\\ttrain: {:d}\\tval: {:d}\".format(len(eeg_dict[p][\"neutral\"][\"train\"]),len(eeg_dict[p][\"neutral\"][\"val\"])))\n",
        "  print(\"sadness:\\ttrain: {:d}\\tval: {:d}\".format(len(eeg_dict[p][\"sadness\"][\"train\"]),len(eeg_dict[p][\"sadness\"][\"val\"])))\n",
        "  print(\"fear:\\t\\ttrain: {:d}\\tval: {:d}\".format(len(eeg_dict[p][\"fear\"][\"train\"]),len(eeg_dict[p][\"fear\"][\"val\"])))\n",
        "  print(\"happiness:\\ttrain: {:d}\\tval: {:d}\".format(len(eeg_dict[p][\"happiness\"][\"train\"]),len(eeg_dict[p][\"happiness\"][\"val\"])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "PATIENT 11\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 8\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 10\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 3\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 12\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 6\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 13\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 2\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 7\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 4\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 1\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 9\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 5\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 15\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n",
            "\n",
            "PATIENT 14\n",
            "neutral:\ttrain: 448\tval: 230\n",
            "sadness:\ttrain: 432\tval: 251\n",
            "fear:\t\ttrain: 419\tval: 196\n",
            "happiness:\ttrain: 388\tval: 141\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZcPRJkfCJu-"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOgpQ_7ZOWh2"
      },
      "source": [
        "eeg_dict=np.load(\"eeg_dict.npy\",allow_pickle=True).item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZkzgRmlOWh2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91f7b618-af0c-462f-bffc-660dd482ffab"
      },
      "source": [
        "adjacency_matrix=get_adjacency_matrix(\"seed_iv/Channel Order.xlsx\",\"seed_iv/Channel Location.txt\")\n",
        "adjacency_matrix=torch.tensor(adjacency_matrix, dtype=torch.float32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Emotions-fromEEG-toArt/seed_iv/seedIV_utils.py:103: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  adjacency_matrix = np.minimum(np.ones([62,62]), delta/(distances_matrix**2))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bvxa--JtOWh3"
      },
      "source": [
        "BATCH_SIZE=8\n",
        "eeg_dataloaders = {}\n",
        "for p in eeg_dict.keys():\n",
        "  eeg_dataloaders[p]={\n",
        "    \"neutral\": {\n",
        "      \"train\": torch_geometric.data.DataLoader(eeg_dict[p][\"neutral\"][\"train\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True),\n",
        "      \"val\": torch_geometric.data.DataLoader(eeg_dict[p][\"neutral\"][\"val\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "    },\n",
        "    \"sadness\": {\n",
        "      \"train\": torch_geometric.data.DataLoader(eeg_dict[p][\"sadness\"][\"train\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True),\n",
        "      \"val\": torch_geometric.data.DataLoader(eeg_dict[p][\"sadness\"][\"val\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "    },\n",
        "    \"fear\": {\n",
        "      \"train\": torch_geometric.data.DataLoader(eeg_dict[p][\"fear\"][\"train\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True),\n",
        "      \"val\": torch_geometric.data.DataLoader(eeg_dict[p][\"fear\"][\"val\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "    },\n",
        "    \"happiness\": {\n",
        "      \"train\": torch_geometric.data.DataLoader(eeg_dict[p][\"happiness\"][\"train\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True),\n",
        "      \"val\": torch_geometric.data.DataLoader(eeg_dict[p][\"happiness\"][\"val\"],batch_size=BATCH_SIZE,shuffle=False,drop_last=True)\n",
        "    }\n",
        "  }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stfr3rGtFaxU"
      },
      "source": [
        "## StyleGAN2-ADA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGlWEdFPFcdN"
      },
      "source": [
        "#IDENTIFY THE VERSION TO COPY-PASTE"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}